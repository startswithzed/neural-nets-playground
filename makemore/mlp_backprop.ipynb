{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Our Own Backward Pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Have So Far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../data/names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(label, dt, t):\n",
    "  \"\"\"Compare gradients calculated by Pytorch and our manual calculation\"\"\"\n",
    "  ex = torch.all(dt==t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt-t.grad).abs().max().item()\n",
    "  print(f'{label:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Params\n",
    "\n",
    "There are a couple of things to notice in our initialization:\n",
    "\n",
    "1. We are initializing many of the params in a non-standard way(normally biases are all zeros). We're doing this because we'll be calculating our gradients manually and sometimes when our params are initialized to zero, they can mask an incorrect implementation of the gradient. To counteract this possibility we have initialized our params to small numbers.\n",
    "\n",
    "2. We are using B1 even though it'll get cancelled out because of batch norm. This is here just for fun. We'll be able to calculate the gradient with respect to it can check that it's working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 64\n",
    "\n",
    "C  = torch.randn((vocab_size, n_embd))\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden)) * (5/3)/((n_embd * block_size)**0.5)\n",
    "B1 = torch.randn(n_hidden) * 0.1 # useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size)) * 0.1\n",
    "B2 = torch.randn(vocab_size) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, B1, W2, B2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass\n",
    "\n",
    "Since we'll manually go backwards through the forward pass to calculate the gradients, we have used more intermediate tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3032, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1)\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + B1\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact)\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + B2\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagating Through Line By Line Through Forward Pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`logprobs`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are prepending derivatives of variables above with a `d`. For example derivative of `logprobs` is `dlogprobs`. `dlogprobs` is the gradient of the loss w.r.t to all the `logprobs` of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 18, 25,  0,  0, 14, 20,  7, 14, 14,  0,  1, 14,  1,  8, 14, 14,  0,\n",
       "        12, 25,  1, 15, 15,  5, 14, 12, 18, 19,  5, 20, 19, 14])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logprobs` is of `dim=(32, 27)` so it's derivative will also be of the same size i.e. `dim=(32, 27)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -logprobs[range(n), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.5060, -2.7486, -2.4663, -3.0699, -3.2036, -2.4438, -3.5328, -3.2617,\n",
       "        -3.0439, -3.8202, -2.7486, -3.0359, -4.2181, -3.6518, -3.8510, -3.3660,\n",
       "        -4.0383, -3.0685, -2.7486, -3.3178, -3.4971, -3.4755, -3.1675, -3.6001,\n",
       "        -3.4447, -3.0768, -1.8435, -4.2654, -3.2072, -3.7865, -4.0949, -3.1025],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[range(n), Yb]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the loss we pluck out `logprobs` at indices `Yb`(the probability for the correct next char in the sequence) and calculate their mean. Which means:\n",
    "`loss = -(a + b + c) / 3.`\n",
    "`loss = -1/3a + -1/3b + -1/3c`\n",
    "`dloss / da = -1/3`\n",
    "\n",
    "So if we have n numbers instead of 3 then `dloss / d(n)` will be `-1/n`. So `dloss / dlogprobs = -1/n` where `n` is the `batch_size`.\n",
    "\n",
    "`logprobs` is `(32, 27)` but only 32 of them participate in the loss calculation so what is the derivative for the other values? Their gradient is 0 because they don't participate in the loss. If we were to change these numbers, the loss wouldn't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs) # Create a tensor in shape of logprobs\n",
    "dlogprobs[range(n), Yb] = -1.0 / n # Gradient of the relevant n values for a given batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if our gradient is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`probs`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logprobs` depend on `probs` through a log function.\n",
    "\n",
    "`logprobs = probs.log()`\n",
    "\n",
    "So we are taking the element-wise log of all the probabilities. So the derivative of probs -> log -> logprobs will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs # chain the derivative of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('probs', dprobs, probs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the derivative of probs we can see that if the network predicts the next character exactly correct probability is 1 and `dprobs` just becomes `dlogprobs`. But if the probability is low than 1 then `dlogprobs` will get boosted by the factor `1/prob`. So this part is boosting the gradients for the samples which have low probs assigned to the correct character."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`dcounts_sum_env`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what's happening after we take our logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + B2\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts * counts_sum_inv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finding the max in each row of the logits and subtracting it to achieve numerical stability because if we don't do this some of the counts take too large values when we exponentiate the logits. Then we take the sum of our counts and normalise them to get the probabilities. So the derivative of `dcounts_sum_inv` will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the shapes don't match, Pytorch will perform the broadcasting operation when we perform `probs = counts * counts_sum_inv`.\n",
    "\n",
    "`c = a * b` where `a[3,3]` and `b[3,1]`\n",
    "`c =` \n",
    "`a11xb1 a12xb1 a13xb1`\n",
    "`a21xb2 a22xb2 a33xb2`\n",
    "`a31xb3 a32xb3 a33xb3` to get `c[3,3]`\n",
    "\n",
    "So pytorch applied two operations to complete this step during the forward pass, replication and then multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum_inv = counts * dprobs # Backprop through multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True) # Backprop through replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`counts`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts = counts_sum_inv * dprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts += torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('counts', dcounts, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`norm_logits`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnorm_logits = counts * dcounts # counts  = norm_logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`logits and logit_maxes`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0268e-09],\n",
       "        [-4.8894e-09],\n",
       "        [-3.7253e-09],\n",
       "        [-2.7940e-09],\n",
       "        [ 9.3132e-10],\n",
       "        [ 1.3970e-09],\n",
       "        [-3.7253e-09],\n",
       "        [ 3.7253e-09],\n",
       "        [-3.0268e-09],\n",
       "        [ 1.3970e-09]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('logits', dlogits, logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`h, W2 and B2`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([27]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits.shape, h.shape, W2.shape, B2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "dB2 = dlogits.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "B2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('h', dh, h)\n",
    "compare('W2', dW2, W2)\n",
    "compare('B2', dB2, B2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`hpreact`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhpreact = (1.0 - h**2) * dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('hpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.shape, bngain.shape, bnraw.shape, bnbias.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bngain, bnraw and bnbias`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bngainh         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bngainh', dbngain, bngain)\n",
    "compare('bnraw', dbnraw, bnraw)\n",
    "compare('bnbias', dbnbias, bnbias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bndiff and bnvar_inv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnraw.shape, bndiff.shape, bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: False | approximate: False | maxdiff: 0.0009200623608194292\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bndiff', dbndiff, bndiff) # expected to be false because we haven't calucated it completely\n",
    "compare('bnvar_inv', dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bnvar`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bnvar', dbnvar, bnvar)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bessel's Correction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the batch norm layer there are two ways to get the variance in a tensor. First is the biased estimate in which we perform `1/n` and the other is `1/(n-1)`. In paper in which they use the biased version during training and the unbiased version during inference.\n",
    "\n",
    "Dividing by `n-1` gives a better estimate of the variance in cases where the sample sizes are very small like in the case of our batches. Estimating using `1/n` almost always underestimates the variance hence it's advised to use the unbiased estimator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop (Contd.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bndiff2`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnvar.shape, bndiff2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff2 = (1.0 / (n-1)) * torch.ones_like(bndiff2) * dbnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bndiff2', dbndiff2, bndiff2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bndiff`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff += (2*bndiff) * dbndiff2 # gradient of second branch for bndiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`hprebn and bnmeani`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff.shape, hprebn.shape, bnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0) # -torch.ones_like(bndiff) * dbndiff = dbndiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: False | maxdiff: 0.0018582979682832956\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('hprebn', dhprebn, hprebn) # expected to be incorrect because there is a second branch\n",
    "compare('bnmeani', dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn +=  (1.0/n) * (torch.ones_like(hprebn) * dbnmeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('hprebn', dhprebn, hprebn) # we have added the second branch of the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, embcat.shape, W1.shape, B1.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`embcat, W1 and B1`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "dB1 = dhprebn.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "B1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('embcat', dembcat, embcat)\n",
    "compare('W1', dW1, W1)\n",
    "compare('B1', dB1, B1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`emb`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([32, 3, 10]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embcat.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "demb = dembcat.view(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('emb', demb, emb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`C`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, C.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('C', dC, C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop Through Simplified Forward Pass(Loss Function)\n",
    "\n",
    "Earlier, we used a lot of intermediate tensors just to form a basic understanding of step by step backprop. When we look at the mathematical expression for the loss and perform the differentiation then a lot of terms cancel out and we get a simplified expression which is significantly easier to backprop through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fast = F.cross_entropy(logits, Yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3032257556915283 diff:  2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "print(loss_fast.item(), 'diff: ', (loss_fast - loss).item())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll differentiate the mathematical form of `cross_entropy` to get a simplified equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits = F.softmax(logits, 1) # softmax across the rows\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 6.51925802230835e-09\n"
     ]
    }
   ],
   "source": [
    "compare('logits', dlogits, logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't get an exact match (because of how floating point numbers work) but the maximum difference is negligible."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What Does `dlogits` Represent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(dlogits.detach(), cmap='Purples');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dlogits` is the gradient of the probability matrix in the forward pass. The white squares represent the correct character indices where we subtracted 1."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the first row we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0347, 0.0640, 0.0560, 0.0295, 0.0239, 0.0213, 0.0365, 0.0309, 0.0222,\n",
       "        0.0281, 0.0259, 0.0300, 0.0476, 0.0854, 0.0464, 0.0429, 0.0459, 0.0154,\n",
       "        0.0319, 0.0583, 0.0263, 0.0165, 0.0290, 0.0328, 0.0295, 0.0633, 0.0257],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0347,  0.0640,  0.0560,  0.0295,  0.0239,  0.0213,  0.0365,  0.0309,\n",
       "         0.0222,  0.0281,  0.0259, -0.9700,  0.0476,  0.0854,  0.0464,  0.0429,\n",
       "         0.0459,  0.0154,  0.0319,  0.0583,  0.0263,  0.0165,  0.0290,  0.0328,\n",
       "         0.0295,  0.0633,  0.0257], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the exact probabilities except at the correct index which is appx -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-6.9849e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum() # This sums to 0 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So because we update our params by `-lr * grads` we are decreasing the probs at the incorrect indices and increasing at the correct index. The amount of this increase and increase is exactly even as shown by the `sum = 0`. The amount of increase/ decrease is proportional to the probs. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
