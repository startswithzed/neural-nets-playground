{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Our Own Backward Pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Have So Far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../data/names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(label, dt, t):\n",
    "  \"\"\"Compare gradients calculated by Pytorch and our manual calculation\"\"\"\n",
    "  ex = torch.all(dt==t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt-t.grad).abs().max().item()\n",
    "  print(f'{label:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Params\n",
    "\n",
    "There are a couple of things to notice in our initialization:\n",
    "\n",
    "1. We are initializing many of the params in a non-standard way(normally biases are all zeros). We're doing this because we'll be calculating our gradients manually and sometimes when our params are initialized to zero, they can mask an incorrect implementation of the gradient. To counteract this possibility we have initialized our params to small numbers.\n",
    "\n",
    "2. We are using B1 even though it'll get cancelled out because of batch norm. This is here just for fun. We'll be able to calculate the gradient with respect to it can check that it's working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 64\n",
    "\n",
    "C  = torch.randn((vocab_size, n_embd))\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden)) * (5/3)/((n_embd * block_size)**0.5)\n",
    "B1 = torch.randn(n_hidden) * 0.1 # useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size)) * 0.1\n",
    "B2 = torch.randn(vocab_size) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, B1, W2, B2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass\n",
    "\n",
    "Since we'll manually go backwards through the forward pass to calculate the gradients, we have used more intermediate tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3937, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1)\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + B1\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact)\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + B2\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagating Through All Variables Manually"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`logprobs`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are prepending derivatives of variables above with a `d`. For example derivative of `logprobs` is `dlogprobs`. `dlogprobs` is the gradient of the loss w.r.t to all the `logprobs` of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 18, 25,  0,  0, 14, 20,  7, 14, 14,  0,  1, 14,  1,  8, 14, 14,  0,\n",
       "        12, 25,  1, 15, 15,  5, 14, 12, 18, 19,  5, 20, 19, 14])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logprobs` is of `dim=(32, 27)` so it's derivative will also be of the same size i.e. `dim=(32, 27)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -logprobs[range(n), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.1692, -3.5540, -3.1044, -3.2213, -3.4846, -2.7099, -3.5018, -2.7046,\n",
       "        -2.8402, -2.4829, -3.4088, -3.9834, -2.8224, -3.5220, -2.9073, -3.4231,\n",
       "        -3.8019, -3.2720, -2.1063, -4.7683, -3.9230, -4.0226, -2.8231, -3.4367,\n",
       "        -3.5057, -3.6846, -3.3293, -3.9010, -3.8229, -3.3987, -3.8660, -4.0978],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[range(n), Yb]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the loss we pluck out `logprobs` at indices `Yb`(the probability for the correct next char in the sequence) and calculate their mean. Which means:\n",
    "`loss = -(a + b + c) / 3.`\n",
    "`loss = -1/3a + -1/3b + -1/3c`\n",
    "`dloss / da = -1/3`\n",
    "\n",
    "So if we have n numbers instead of 3 then `dloss / d(n)` will be `-1/n`. So `dloss / dlogprobs = -1/n` where `n` is the `batch_size`.\n",
    "\n",
    "`logprobs` is `(32, 27)` but only 32 of them participate in the loss calculation so what is the derivative for the other values? Their gradient is 0 because they don't participate in the loss. If we were to change these numbers, the loss wouldn't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs) # Create a tensor in shape of logprobs\n",
    "dlogprobs[range(n), Yb] = -1.0 / n # Gradient of the relevant n values for a given batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if our gradient is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`probs`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logprobs` depend on `probs` through a log function.\n",
    "\n",
    "`logprobs = probs.log()`\n",
    "\n",
    "So we are taking the element-wise log of all the probabilities. So the derivative of probs -> log -> logprobs will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs # chain the derivative of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('probs', dprobs, probs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the derivative of probs we can see that if the network predicts the next character exactly correct probability is 1 and `dprobs` just becomes `dlogprobs`. But if the probability is low than 1 then `dlogprobs` will get boosted by the factor `1/prob`. So this part is boosting the gradients for the samples which have low probs assigned to the correct character."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`dcounts_sum_env`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what's happening after we take our logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + B2\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts * counts_sum_inv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finding the max in each row of the logits and subtracting it to achieve numerical stability because if we don't do this some of the counts take too large values when we exponentiate the logits. Then we take the sum of our counts and normalise them to get the probabilities. So the derivative of `dcounts_sum_inv` will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the shapes don't match, Pytorch will perform the broadcasting operation when we perform `probs = counts * counts_sum_inv`.\n",
    "\n",
    "`c = a * b` where `a[3,3]` and `b[3,1]`\n",
    "`c =` \n",
    "`a11xb1 a12xb1 a13xb1`\n",
    "`a21xb2 a22xb2 a33xb2`\n",
    "`a31xb3 a32xb3 a33xb3` to get `c[3,3]`\n",
    "\n",
    "So pytorch applied two operations to complete this step during the forward pass, replication and then multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum_inv = counts * dprobs # Backprop through multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True) # Backprop through replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`counts`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts = counts_sum_inv * dprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts += torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('counts', dcounts, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnorm_logits = counts * dcounts # counts  = norm_logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.7253e-09],\n",
       "        [ 1.1642e-09],\n",
       "        [-9.3132e-10],\n",
       "        [ 2.0955e-09],\n",
       "        [-5.1223e-09],\n",
       "        [ 3.2596e-09],\n",
       "        [-4.1910e-09],\n",
       "        [-1.8626e-09],\n",
       "        [-3.2596e-09],\n",
       "        [-4.6566e-10]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('logits', dlogits, logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([27]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits.shape, h.shape, W2.shape, B2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "dB2 = dlogits.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "B2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('h', dh, h)\n",
    "compare('W2', dW2, W2)\n",
    "compare('B2', dB2, B2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhpreact = (1.0 - h**2) * dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('hpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.shape, bngain.shape, bnraw.shape, bnbias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bngainh         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bngainh', dbngain, bngain)\n",
    "compare('bnraw', dbnraw, bnraw)\n",
    "compare('bnbias', dbnbias, bnbias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnraw.shape, bndiff.shape, bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: False | approximate: False | maxdiff: 0.0009200623608194292\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bndiff', dbndiff, bndiff) # expected to be false because we haven't calucated it completely\n",
    "compare('bnvar_inv', dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bnvar', dbnvar, bnvar)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
