{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Our Own Backward Pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What We Have So Far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = open('../data/names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'a', 2: 'b', 3: 'c', 4: 'd', 5: 'e', 6: 'f', 7: 'g', 8: 'h', 9: 'i', 10: 'j', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'q', 18: 'r', 19: 's', 20: 't', 21: 'u', 22: 'v', 23: 'w', 24: 'x', 25: 'y', 26: 'z', 0: '.'}\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182625, 3]) torch.Size([182625])\n",
      "torch.Size([22655, 3]) torch.Size([22655])\n",
      "torch.Size([22866, 3]) torch.Size([22866])\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "\n",
    "def build_dataset(words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(words)\n",
    "n1 = int(0.8*len(words))\n",
    "n2 = int(0.9*len(words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(label, dt, t):\n",
    "  \"\"\"Compare gradients calculated by Pytorch and our manual calculation\"\"\"\n",
    "  ex = torch.all(dt==t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt-t.grad).abs().max().item()\n",
    "  print(f'{label:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init Params\n",
    "\n",
    "There are a couple of things to notice in our initialization:\n",
    "\n",
    "1. We are initializing many of the params in a non-standard way(normally biases are all zeros). We're doing this because we'll be calculating our gradients manually and sometimes when our params are initialized to zero, they can mask an incorrect implementation of the gradient. To counteract this possibility we have initialized our params to small numbers.\n",
    "\n",
    "2. We are using B1 even though it'll get cancelled out because of batch norm. This is here just for fun. We'll be able to calculate the gradient with respect to it can check that it's working properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4137\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10\n",
    "n_hidden = 64\n",
    "\n",
    "C  = torch.randn((vocab_size, n_embd))\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden)) * (5/3)/((n_embd * block_size)**0.5)\n",
    "B1 = torch.randn(n_hidden) * 0.1 # useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size)) * 0.1\n",
    "B2 = torch.randn(vocab_size) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, B1, W2, B2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters))\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create A Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size\n",
    "\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Pass\n",
    "\n",
    "Since we'll manually go backwards through the forward pass to calculate the gradients, we have used more intermediate tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3032, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb = C[Xb]\n",
    "embcat = emb.view(emb.shape[0], -1)\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + B1\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact)\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + B2\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv,\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagating Through Line By Line Through Forward Pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`logprobs`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are prepending derivatives of variables above with a `d`. For example derivative of `logprobs` is `dlogprobs`. `dlogprobs` is the gradient of the loss w.r.t to all the `logprobs` of the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 27])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21, 18, 25,  0,  0, 14, 20,  7, 14, 14,  0,  1, 14,  1,  8, 14, 14,  0,\n",
       "        12, 25,  1, 15, 15,  5, 14, 12, 18, 19,  5, 20, 19, 14])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logprobs` is of `dim=(32, 27)` so it's derivative will also be of the same size i.e. `dim=(32, 27)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = -logprobs[range(n), Yb].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.5060, -2.7486, -2.4663, -3.0699, -3.2036, -2.4438, -3.5328, -3.2617,\n",
       "        -3.0439, -3.8202, -2.7486, -3.0359, -4.2181, -3.6518, -3.8510, -3.3660,\n",
       "        -4.0383, -3.0685, -2.7486, -3.3178, -3.4971, -3.4755, -3.1675, -3.6001,\n",
       "        -3.4447, -3.0768, -1.8435, -4.2654, -3.2072, -3.7865, -4.0949, -3.1025],\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logprobs[range(n), Yb]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the loss we pluck out `logprobs` at indices `Yb`(the probability for the correct next char in the sequence) and calculate their mean. Which means:\n",
    "`loss = -(a + b + c) / 3.`\n",
    "`loss = -1/3a + -1/3b + -1/3c`\n",
    "`dloss / da = -1/3`\n",
    "\n",
    "So if we have n numbers instead of 3 then `dloss / d(n)` will be `-1/n`. So `dloss / dlogprobs = -1/n` where `n` is the `batch_size`.\n",
    "\n",
    "`logprobs` is `(32, 27)` but only 32 of them participate in the loss calculation so what is the derivative for the other values? Their gradient is 0 because they don't participate in the loss. If we were to change these numbers, the loss wouldn't change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogprobs = torch.zeros_like(logprobs) # Create a tensor in shape of logprobs\n",
    "dlogprobs[range(n), Yb] = -1.0 / n # Gradient of the relevant n values for a given batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if our gradient is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('logprobs', dlogprobs, logprobs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`probs`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`logprobs` depend on `probs` through a log function.\n",
    "\n",
    "`logprobs = probs.log()`\n",
    "\n",
    "So we are taking the element-wise log of all the probabilities. So the derivative of probs -> log -> logprobs will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dprobs = (1.0 / probs) * dlogprobs # chain the derivative of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('probs', dprobs, probs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the derivative of probs we can see that if the network predicts the next character exactly correct probability is 1 and `dprobs` just becomes `dlogprobs`. But if the probability is low than 1 then `dlogprobs` will get boosted by the factor `1/prob`. So this part is boosting the gradients for the samples which have low probs assigned to the correct character."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`dcounts_sum_env`**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what's happening after we take our logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = h @ W2 + B2\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1\n",
    "probs = counts * counts_sum_inv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are finding the max in each row of the logits and subtracting it to achieve numerical stability because if we don't do this some of the counts take too large values when we exponentiate the logits. Then we take the sum of our counts and normalise them to get the probabilities. So the derivative of `dcounts_sum_inv` will be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum_inv.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the shapes don't match, Pytorch will perform the broadcasting operation when we perform `probs = counts * counts_sum_inv`.\n",
    "\n",
    "`c = a * b` where `a[3,3]` and `b[3,1]`\n",
    "`c =` \n",
    "`a11xb1 a12xb1 a13xb1`\n",
    "`a21xb2 a22xb2 a33xb2`\n",
    "`a31xb3 a32xb3 a33xb3` to get `c[3,3]`\n",
    "\n",
    "So pytorch applied two operations to complete this step during the forward pass, replication and then multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum_inv = counts * dprobs # Backprop through multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True) # Backprop through replication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`counts`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts = counts_sum_inv * dprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('counts_sum', dcounts_sum, counts_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.shape, counts_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcounts += torch.ones_like(counts) * dcounts_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('counts', dcounts, counts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`norm_logits`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnorm_logits = counts * dcounts # counts  = norm_logits.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('norm_logits', dnorm_logits, norm_logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`logits and logit_maxes`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]), torch.Size([32, 27]), torch.Size([32, 1]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_logits.shape, logits.shape, logit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('logit_maxes', dlogit_maxes, logit_maxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0268e-09],\n",
       "        [-4.8894e-09],\n",
       "        [-3.7253e-09],\n",
       "        [-2.7940e-09],\n",
       "        [ 9.3132e-10],\n",
       "        [ 1.3970e-09],\n",
       "        [-3.7253e-09],\n",
       "        [ 3.7253e-09],\n",
       "        [-3.0268e-09],\n",
       "        [ 1.3970e-09]], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogit_maxes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('logits', dlogits, logits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`h, W2 and B2`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 27]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64, 27]),\n",
       " torch.Size([27]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits.shape, h.shape, W2.shape, B2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "dB2 = dlogits.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "B2              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('h', dh, h)\n",
    "compare('W2', dW2, W2)\n",
    "compare('B2', dB2, B2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`hpreact`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhpreact = (1.0 - h**2) * dh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('hpreact', dhpreact, hpreact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([1, 64]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hpreact.shape, bngain.shape, bnraw.shape, bnbias.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bngain, bnraw and bnbias`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bngainh         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bngainh', dbngain, bngain)\n",
    "compare('bnraw', dbnraw, bnraw)\n",
    "compare('bnbias', dbnbias, bnbias)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bndiff and bnvar_inv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnraw.shape, bndiff.shape, bnvar_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: False | approximate: False | maxdiff: 0.0009200623608194292\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bndiff', dbndiff, bndiff) # expected to be false because we haven't calucated it completely\n",
    "compare('bnvar_inv', dbnvar_inv, bnvar_inv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bnvar`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bnvar', dbnvar, bnvar)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bessel's Correction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the batch norm layer there are two ways to get the variance in a tensor. First is the biased estimate in which we perform `1/n` and the other is `1/(n-1)`. In paper in which they use the biased version during training and the unbiased version during inference.\n",
    "\n",
    "Dividing by `n-1` gives a better estimate of the variance in cases where the sample sizes are very small like in the case of our batches. Estimating using `1/n` almost always underestimates the variance hence it's advised to use the unbiased estimator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprop (Contd.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bndiff2`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 64]), torch.Size([32, 64]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnvar.shape, bndiff2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff2 = (1.0 / (n-1)) * torch.ones_like(bndiff2) * dbnvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bndiff2', dbndiff2, bndiff2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bndiff`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbndiff += (2*bndiff) * dbndiff2 # gradient of second branch for bndiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('bndiff', dbndiff, bndiff)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`hprebn and bnmeani`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]), torch.Size([32, 64]), torch.Size([1, 64]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bndiff.shape, hprebn.shape, bnmeani.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0) # -torch.ones_like(bndiff) * dbndiff = dbndiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: False | maxdiff: 0.0018582979682832956\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('hprebn', dhprebn, hprebn) # expected to be incorrect because there is a second branch\n",
    "compare('bnmeani', dbnmeani, bnmeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhprebn +=  (1.0/n) * (torch.ones_like(hprebn) * dbnmeani)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('hprebn', dhprebn, hprebn) # we have added the second branch of the gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([32, 30]),\n",
       " torch.Size([30, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hprebn.shape, embcat.shape, W1.shape, B1.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`embcat, W1 and B1`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "dB1 = dhprebn.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "B1              | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('embcat', dembcat, embcat)\n",
    "compare('W1', dW1, W1)\n",
    "compare('B1', dB1, B1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`emb`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 30]), torch.Size([32, 3, 10]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embcat.shape, emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "demb = dembcat.view(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('emb', demb, emb)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`C`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 10]), torch.Size([27, 10]), torch.Size([32, 3]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape, C.shape, Xb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "    for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "compare('C', dC, C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
