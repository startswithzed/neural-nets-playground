{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "!pip install -Uqq torch\n",
    "!pip install -Uqq numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Raw Implementation Of GPT Like Model\n",
    "### Download The Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-08 12:25:10--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1115394 (1.1M) [text/plain]\r\n",
      "Saving to: ‘input.txt’\r\n",
      "\r\n",
      "input.txt           100%[===================>]   1.06M  1.79MB/s    in 0.6s    \r\n",
      "\r\n",
      "2023-03-08 12:25:12 (1.79 MB/s) - ‘input.txt’ saved [1115394/1115394]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "with open('data/tinyshakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect The Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "1115394"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first 1000 characters\n",
    "print(text[:1000])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get The Vocabulary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    },
    {
     "data": {
      "text/plain": "65"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get set of all chars in the text and then get that as a sorted list\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "vocab_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenize The Input\n",
    "Since this is a character level language model, we'll just translate individual characters to integers.\n",
    "\n",
    "Other tokenizers to look into:\n",
    "1. SentencePiece (Google)\n",
    "2. Tiktoken (OpenAI)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42, 2]\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # take a string and output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # take a list of integers and output a string\n",
    "\n",
    "print(encode(\"Hello World!\"))\n",
    "print(decode(encode(\"Hello World!\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stoi is a lookup table where key is the index and value is the character\n",
    "type(stoi)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# encode the dataset and get a tensor\n",
    "# data type is int16 because our vocab size is only 65\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Training and Validation Splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "(1003854, 111540)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(0.9*len(data)) # split 90% of data\n",
    "train_data = data[:n] # first 90% is training data\n",
    "val_data = data[n:] # rest is validation data\n",
    "\n",
    "len(train_data), len(val_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Batches Of Data To Train The Model\n",
    "\n",
    "Sample random chunks of data from the training set. These chunks are of fixed max length.\n",
    "In a chunk of 9 characters like `[18, 47, 56, 57, 58,  1, 15, 47, 58]` there are 8 examples for the model to train itself on like:\n",
    "1. In the context of 18, 47 likely comes next.\n",
    "2. In the context of 18 and 47, 56 likely comes next and so on.\n",
    "\n",
    "This also helps the transformer network get used to seeing context length of 1 character upto the max context length."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 # max length of chunks\n",
    "train_data[:block_size + 1] # first 9 chars in the training set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([18])\ttarget: 47\n",
      "input: tensor([18, 47])\ttarget: 56\n",
      "input: tensor([18, 47, 56])\ttarget: 57\n",
      "input: tensor([18, 47, 56, 57])\ttarget: 58\n",
      "input: tensor([18, 47, 56, 57, 58])\ttarget: 1\n",
      "input: tensor([18, 47, 56, 57, 58,  1])\ttarget: 15\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15])\ttarget: 47\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15, 47])\ttarget: 58\n"
     ]
    }
   ],
   "source": [
    "# x are the inputs to the transformer\n",
    "x = train_data[:block_size]\n",
    "# y is the next block\n",
    "y = train_data[1:block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1] # all chars of x upto t incl. t\n",
    "    target = y[t]\n",
    "    print(f'input: {context}\\ttarget: {target}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# add batching to process multiple inputs simultaneously\n",
    "batch_size = 4 # number of independent sequences to be processed parallely\n",
    "block_size = 8 # max length of the context\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # generate batch_size number of random offsets in the dataset\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # stack converts multiple rows into a list of rows\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x,y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[63,  1, 51, 43, 61,  5, 42,  1],\n",
      "        [59,  1, 42, 43, 40, 39, 57, 43],\n",
      "        [39,  1, 42, 59, 49, 43, 42, 53],\n",
      "        [51, 47, 56, 58, 46,  8,  0,  0]])\n",
      "inputs_shape: torch.Size([4, 8])\n",
      "\n",
      "targets: tensor([[ 1, 51, 43, 61,  5, 42,  1, 46],\n",
      "        [ 1, 42, 43, 40, 39, 57, 43,  1],\n",
      "        [ 1, 42, 59, 49, 43, 42, 53, 51],\n",
      "        [47, 56, 58, 46,  8,  0,  0, 34]])\n",
      "targets_shape: torch.Size([4, 8])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example batches\n",
    "xb, yb = get_batch('train')\n",
    "print(f'inputs: {xb}\\ninputs_shape: {xb.shape}\\n')\n",
    "print(f'targets: {yb}\\ntargets_shape: {yb.shape}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [53]\ttarget: 51\n",
      "input: [53, 51]\ttarget: 39\n",
      "input: [53, 51, 39]\ttarget: 52\n",
      "input: [53, 51, 39, 52]\ttarget: 11\n",
      "input: [53, 51, 39, 52, 11]\ttarget: 1\n",
      "input: [53, 51, 39, 52, 11, 1]\ttarget: 47\n",
      "input: [53, 51, 39, 52, 11, 1, 47]\ttarget: 44\n",
      "input: [53, 51, 39, 52, 11, 1, 47, 44]\ttarget: 1\n",
      "input: [53]\ttarget: 53\n",
      "input: [53, 53]\ttarget: 51\n",
      "input: [53, 53, 51]\ttarget: 10\n",
      "input: [53, 53, 51, 10]\ttarget: 0\n",
      "input: [53, 53, 51, 10, 0]\ttarget: 35\n",
      "input: [53, 53, 51, 10, 0, 35]\ttarget: 46\n",
      "input: [53, 53, 51, 10, 0, 35, 46]\ttarget: 39\n",
      "input: [53, 53, 51, 10, 0, 35, 46, 39]\ttarget: 58\n",
      "input: [53]\ttarget: 49\n",
      "input: [53, 49]\ttarget: 1\n",
      "input: [53, 49, 1]\ttarget: 47\n",
      "input: [53, 49, 1, 47]\ttarget: 52\n",
      "input: [53, 49, 1, 47, 52]\ttarget: 42\n",
      "input: [53, 49, 1, 47, 52, 42]\ttarget: 43\n",
      "input: [53, 49, 1, 47, 52, 42, 43]\ttarget: 43\n",
      "input: [53, 49, 1, 47, 52, 42, 43, 43]\ttarget: 42\n",
      "input: [43]\ttarget: 1\n",
      "input: [43, 1]\ttarget: 53\n",
      "input: [43, 1, 53]\ttarget: 58\n",
      "input: [43, 1, 53, 58]\ttarget: 46\n",
      "input: [43, 1, 53, 58, 46]\ttarget: 43\n",
      "input: [43, 1, 53, 58, 46, 43]\ttarget: 56\n",
      "input: [43, 1, 53, 58, 46, 43, 56]\ttarget: 0\n",
      "input: [43, 1, 53, 58, 46, 43, 56, 0]\ttarget: 57\n"
     ]
    }
   ],
   "source": [
    "# input and target mapping for batches\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'input: {context.tolist()}\\ttarget: {target}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bigram Language Model As A Baseline Model\n",
    "\n",
    "Right now we're only predicting what comes next based on just the individual identity of a single token. This is because the tokens aren't aware of each other. They can only see themselves. So we're only making predictions based on what the actual token is.\n",
    "\n",
    "Notice that in the implementation of generate method even though we pass a sequence of characters as context, the Bigram model only looks at the last character in the sequence to make predictions for the next character. The generate method accepts a sequence as context to keep it general."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # logits are basically the scores for the next character in a sequence\n",
    "        # channel means all the possible tokens (here chars) you can have\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C) Batch, Time, Channel\n",
    "\n",
    "        # loss function\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # logits need to be reshaped because cross_entropy expects channels as the second dimension\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            # cross_entropy calculates loss a -log likelihood: -ln(char/65)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    # idx is the current context of some characters\n",
    "    # generate function extends the input (B, T) to B by T+1, T+2 and so on...\n",
    "    # and continues to do so for max_new_tokens\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get predictions\n",
    "            logits, _ = self(idx)\n",
    "            # focus only on the last element in the time dimension\n",
    "            logits = logits[:, -1, :]\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            # sample from the probability distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "\n",
    "        return idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([[-0.9729,  0.2434, -0.1356,  ...,  0.1614, -1.3162, -0.0710],\n",
      "        [-1.3694,  0.4819, -0.6065,  ...,  1.4325,  2.7159, -0.2356],\n",
      "        [ 2.1531, -1.6002,  0.9560,  ...,  0.2818,  1.5296,  0.7737],\n",
      "        ...,\n",
      "        [ 0.5601, -2.4942, -1.4284,  ...,  0.2002, -1.6565,  0.5220],\n",
      "        [ 1.9211, -0.2959,  1.6537,  ..., -0.5056,  0.7793,  0.9916],\n",
      "        [-0.1882,  0.4575,  0.3669,  ..., -0.2465, -1.4268, -0.8499]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "loss: 4.5496134757995605\n",
      "torch.Size([32, 65])\n"
     ]
    }
   ],
   "source": [
    "# example prediction\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(f'logits: {logits}\\nloss: {loss}\\n{logits.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BL&xr\n",
      "rwv!IepVIlbjFAHzCYJifXG&3&!a;pCZntuF;YjfRAuFAl;:lGJXTPYn!HM-- sWmJdL&NfcVJdF$nMvzbYjgvUpb'?vpC\n"
     ]
    }
   ],
   "source": [
    "# example generation\n",
    "# B = 1 and T = 1 to kick off the generation\n",
    "# 0 is also encoded as \\n, which is a good place to start\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist())) #[0] to get a single batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training The Bigram Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# creating a pytorch optimizer to get the gradients and update the parameters\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.4108874797821045\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'loss: {loss.item()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NGowerarisaxed, f I s m fouiethan ond mellchashe the THe orongendy'le, k, nk merp er q$ffffos, twidy\n",
      "A:\n",
      "Cousfress sefthe ma nd theaw'swate ghered,\n",
      "I\n",
      "Aur KETor byerin fame oGS:\n",
      "lee.\n",
      "NRFre:\n",
      "I messen:\n",
      "Cor D&\n",
      "Cl\n",
      "YWhind, her bee ted t, w trd Cotltixet ce t HENG me.\n",
      "s worede of bor t tosesthesoicassw ay ir oukipserfonove; y Gise.\n",
      "Wharar:\n",
      "Whiro th.\n",
      "W: ceandutous rtiffomy\n",
      "\n",
      "VI wemofancat r,\n",
      "Coen wher moner\n"
     ]
    }
   ],
   "source": [
    "# test generation\n",
    "print(decode(m.generate(idx, max_new_tokens=400)[0].tolist()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementing Self Attention\n",
    "We want the tokens to be aware of each other. Specifically we want the current token to be aware of the tokens that have appeared before (and not the tokens that come after) and couple them. To do that we calculate the average of all the previous token which then acts as the summary of all the information before the current token which it can use to predict the next token. Keep in mind this approach loses out on a lot of spacial information about the previous tokens."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x: torch.Size([4, 8, 2])\n",
      "\n",
      "x: tensor([[[-0.5064, -0.8704],\n",
      "         [ 0.2256, -0.6402],\n",
      "         [-0.6735,  1.1263],\n",
      "         [-0.2469, -0.6209],\n",
      "         [ 1.8725,  0.1073],\n",
      "         [ 0.0131,  1.2031],\n",
      "         [ 1.0011,  0.9082],\n",
      "         [ 1.0427, -0.4253]],\n",
      "\n",
      "        [[ 0.7450,  0.3972],\n",
      "         [ 1.0596,  0.4509],\n",
      "         [-1.7042,  0.4181],\n",
      "         [ 0.9725, -0.7836],\n",
      "         [ 0.2181, -0.6505],\n",
      "         [-1.6790, -0.2189],\n",
      "         [-0.5362,  0.4421],\n",
      "         [-0.5073, -0.4883]],\n",
      "\n",
      "        [[ 0.8481, -0.9877],\n",
      "         [ 0.6018, -1.3321],\n",
      "         [ 0.7131, -1.4039],\n",
      "         [ 2.3594, -1.2647],\n",
      "         [ 0.4230, -0.4270],\n",
      "         [ 0.5923,  1.3385],\n",
      "         [-0.0307,  0.2107],\n",
      "         [-0.4659, -0.2931]],\n",
      "\n",
      "        [[ 0.0439, -2.2378],\n",
      "         [ 0.5821, -1.7240],\n",
      "         [-2.1801,  0.0250],\n",
      "         [-0.6911, -0.1005],\n",
      "         [ 0.5991, -0.4966],\n",
      "         [ 0.6118,  0.1392],\n",
      "         [ 0.2605, -0.5143],\n",
      "         [ 0.0079,  0.6442]]])\n",
      "\n",
      "first batch is: tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402],\n",
      "        [-0.6735,  1.1263],\n",
      "        [-0.2469, -0.6209],\n",
      "        [ 1.8725,  0.1073],\n",
      "        [ 0.0131,  1.2031],\n",
      "        [ 1.0011,  0.9082],\n",
      "        [ 1.0427, -0.4253]])\n",
      "num sequences (T) in each batch: 8\n",
      "\n",
      "num tokens (C) in each sequence: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# consider an example sample\n",
    "# B represents number of batchs\n",
    "# T represents number of sequences of tokens in each batch\n",
    "# C represents the number of token embeddings in each sequence\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "print(f'shape of x: {x.shape}\\n')\n",
    "print(f'x: {x}\\n')\n",
    "print(f'first batch is: {x[0]}')\n",
    "B, T, C = x.shape\n",
    "print(f'num sequences (T) in each batch: {T}\\n')\n",
    "print(f'num tokens (C) in each sequence: {C}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the above sample:\n",
    "1. x is a list of batches of tokens from the input text. N(batches) = B. Each batch in our case is a random sample from the input text. This means x is the encoded form of a sequence of characters from somewhere in the text.\n",
    "2. These sequences , in encoded form, are of fixed number of tokens and are layered one after the other in a batch. N(sequences in a batch) = T.\n",
    "3. Each sequence is an ordered list of individual tokens that are present in the sequence. N(tokens in a sequence) = C. Therefore the dimention C contains the information about the position and value of a token in a randomly sampled sequence of tokenized text.\n",
    "\n",
    "The cell below shows a batch from the input text to compare a batch from our random sample:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch from training input:\n",
      "tensor([[63,  1, 51, 43, 61,  5, 42,  1],\n",
      "        [59,  1, 42, 43, 40, 39, 57, 43],\n",
      "        [39,  1, 42, 59, 49, 43, 42, 53],\n",
      "        [51, 47, 56, 58, 46,  8,  0,  0]])\n",
      "\n",
      "shape of each batch: torch.Size([4, 8])\n",
      "\n",
      "num sequences (T) in each batch: 4\n",
      "\n",
      "num tokens (C) in each sequence: 8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a batch from the training set\n",
    "print(f'batch from training input:\\n{xb}\\n')\n",
    "print(f'shape of each batch: {xb.shape}\\n')\n",
    "T, C = xb.shape\n",
    "print(f'num sequences (T) in each batch: {T}\\n')\n",
    "print(f'num tokens (C) in each sequence: {C}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Self Attention V1\n",
    "We'll calculate the average of all tokens in a sequence preceding the current token and including the current token to couple the context with the token. This is how a current token can become aware of the previous tokens in its sequence.\n",
    "\n",
    "Keep in mind this way of communicating context is extremely lossy. We lose out on information about the spacial arrangement of all the tokens in that sequence, we can only see the average."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbow for the sample:\n",
      "tensor([[[-0.5064, -0.8704],\n",
      "         [-0.1404, -0.7553],\n",
      "         [-0.3181, -0.1281],\n",
      "         [-0.3003, -0.2513],\n",
      "         [ 0.1343, -0.1796],\n",
      "         [ 0.1141,  0.0509],\n",
      "         [ 0.2408,  0.1734],\n",
      "         [ 0.3410,  0.0985]],\n",
      "\n",
      "        [[ 0.7450,  0.3972],\n",
      "         [ 0.9023,  0.4240],\n",
      "         [ 0.0335,  0.4220],\n",
      "         [ 0.2682,  0.1206],\n",
      "         [ 0.2582, -0.0336],\n",
      "         [-0.0647, -0.0645],\n",
      "         [-0.1320,  0.0079],\n",
      "         [-0.1789, -0.0541]],\n",
      "\n",
      "        [[ 0.8481, -0.9877],\n",
      "         [ 0.7249, -1.1599],\n",
      "         [ 0.7210, -1.2412],\n",
      "         [ 1.1306, -1.2471],\n",
      "         [ 0.9891, -1.0831],\n",
      "         [ 0.9229, -0.6795],\n",
      "         [ 0.7867, -0.5523],\n",
      "         [ 0.6301, -0.5199]],\n",
      "\n",
      "        [[ 0.0439, -2.2378],\n",
      "         [ 0.3130, -1.9809],\n",
      "         [-0.5180, -1.3123],\n",
      "         [-0.5613, -1.0093],\n",
      "         [-0.3292, -0.9068],\n",
      "         [-0.1724, -0.7324],\n",
      "         [-0.1106, -0.7013],\n",
      "         [-0.0957, -0.5331]]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calc average of prev tokens\n",
    "# this implementation is inefficient\n",
    "xbow = torch.zeros((B, T, C)) # bow means bag of words i.e. average of the prev tokens\n",
    "\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # everything upto the current token including the current token\n",
    "        xbow[b, t] = torch.mean(xprev, 0)\n",
    "\n",
    "print(f'xbow for the sample:\\n{xbow}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Understanding What's Happening In The Above Loop\n",
    "\n",
    "For each batch we are creating a new tensor xprev which stores all the previous sequences upto an including the current sequence(looping across T dim). The bow sequence (values in T dim) for each sequence will be the mean of the corresponding xprev.\n",
    "\n",
    "Question: The mean is calculated only across the 0th dim. Does this mean that we are only calculating the average of the tokens in the same index for previous sequences? Is the context only moving vertically instead of horizontally?\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_batch:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402],\n",
      "        [-0.6735,  1.1263],\n",
      "        [-0.2469, -0.6209],\n",
      "        [ 1.8725,  0.1073],\n",
      "        [ 0.0131,  1.2031],\n",
      "        [ 1.0011,  0.9082],\n",
      "        [ 1.0427, -0.4253]])\n",
      "\n",
      "sequences before and including current sequence:\n",
      "tensor([[-0.5064, -0.8704]])\n",
      "\n",
      "sequences before and including current sequence:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402]])\n",
      "\n",
      "sequences before and including current sequence:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402],\n",
      "        [-0.6735,  1.1263]])\n",
      "\n",
      "sequences before and including current sequence:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402],\n",
      "        [-0.6735,  1.1263],\n",
      "        [-0.2469, -0.6209]])\n",
      "\n",
      "sequences before and including current sequence:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402],\n",
      "        [-0.6735,  1.1263],\n",
      "        [-0.2469, -0.6209],\n",
      "        [ 1.8725,  0.1073]])\n",
      "\n",
      "sequences before and including current sequence:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402],\n",
      "        [-0.6735,  1.1263],\n",
      "        [-0.2469, -0.6209],\n",
      "        [ 1.8725,  0.1073],\n",
      "        [ 0.0131,  1.2031]])\n",
      "\n",
      "sequences before and including current sequence:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402],\n",
      "        [-0.6735,  1.1263],\n",
      "        [-0.2469, -0.6209],\n",
      "        [ 1.8725,  0.1073],\n",
      "        [ 0.0131,  1.2031],\n",
      "        [ 1.0011,  0.9082]])\n",
      "\n",
      "sequences before and including current sequence:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402],\n",
      "        [-0.6735,  1.1263],\n",
      "        [-0.2469, -0.6209],\n",
      "        [ 1.8725,  0.1073],\n",
      "        [ 0.0131,  1.2031],\n",
      "        [ 1.0011,  0.9082],\n",
      "        [ 1.0427, -0.4253]])\n",
      "\n",
      "example xbow:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [-0.1404, -0.7553],\n",
      "        [-0.3181, -0.1281],\n",
      "        [-0.3003, -0.2513],\n",
      "        [ 0.1343, -0.1796],\n",
      "        [ 0.1141,  0.0509],\n",
      "        [ 0.2408,  0.1734],\n",
      "        [ 0.3410,  0.0985]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_xbow = torch.zeros((T, C))\n",
    "first_batch = x[0]\n",
    "print(f'first_batch:\\n{first_batch}\\n')\n",
    "\n",
    "for t in range(T):\n",
    "    xprev = first_batch[:t+1]\n",
    "    print(f'sequences before and including current sequence:\\n{xprev}\\n')\n",
    "    example_xbow[t] = torch.mean(xprev, 0) # take the mean of all the token sequences in the 0th dim\n",
    "\n",
    "print(f'example xbow:\\n{example_xbow}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first batch:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [ 0.2256, -0.6402],\n",
      "        [-0.6735,  1.1263],\n",
      "        [-0.2469, -0.6209],\n",
      "        [ 1.8725,  0.1073],\n",
      "        [ 0.0131,  1.2031],\n",
      "        [ 1.0011,  0.9082],\n",
      "        [ 1.0427, -0.4253]])\n",
      "\n",
      "xbow for the first batch:\n",
      "tensor([[-0.5064, -0.8704],\n",
      "        [-0.1404, -0.7553],\n",
      "        [-0.3181, -0.1281],\n",
      "        [-0.3003, -0.2513],\n",
      "        [ 0.1343, -0.1796],\n",
      "        [ 0.1141,  0.0509],\n",
      "        [ 0.2408,  0.1734],\n",
      "        [ 0.3410,  0.0985]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first batch and its corresponding xbow\n",
    "x[0], xbow[0]\n",
    "print(f'first batch:\\n{x[0]}\\n')\n",
    "print(f'xbow for the first batch:\\n{xbow[0]}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using Matrix Multiplication To Make Average Calculation More Efficient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix a:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "matrix b:\n",
      "tensor([[5., 5.],\n",
      "        [0., 6.],\n",
      "        [6., 4.]])\n",
      "matrix c:\n",
      "tensor([[11., 15.],\n",
      "        [11., 15.],\n",
      "        [11., 15.]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication example\n",
    "\n",
    "# we are multiplying row i of a with column i of b\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(f'matrix a:\\n{a}')\n",
    "print(f'matrix b:\\n{b}')\n",
    "print(f'matrix c:\\n{c}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.],\n        [1., 1., 0.],\n        [1., 1., 1.]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting a lower triangular matrix\n",
    "torch.tril(torch.ones(3, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Performing MatMul Using A Lower Triangular Matrix\n",
    "\n",
    "When we multiply by a tril matrix of ones then the resultant matrix is a matrix in which each element is a sum of only the elements in the previous and current rows(in the corresponding column). So we can use this to calculate mean by using MatMul which is much faster than looping. By dividing each row by its sum (in the 1th dim) and then performing MatMul we'll get xbow."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix a:\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "matrix b:\n",
      "tensor([[8., 5.],\n",
      "        [6., 1.],\n",
      "        [5., 9.]])\n",
      "matrix c:\n",
      "tensor([[ 8.,  5.],\n",
      "        [14.,  6.],\n",
      "        [19., 15.]])\n"
     ]
    }
   ],
   "source": [
    "# performing multiplication with a tril matrix\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(f'matrix a:\\n{a}')\n",
    "print(f'matrix b:\\n{b}')\n",
    "print(f'matrix c:\\n{c}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix a:\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "matrix b:\n",
      "tensor([[3., 1.],\n",
      "        [9., 5.],\n",
      "        [1., 7.]])\n",
      "matrix c:\n",
      "tensor([[3.0000, 1.0000],\n",
      "        [6.0000, 3.0000],\n",
      "        [4.3333, 4.3333]])\n"
     ]
    }
   ],
   "source": [
    "# using a lower triangular matrix gives each element in c matrix as sum of prev elements upon matrix multiplication\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True) # normalize each row such that sum of all elements in a row is one\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b # in c each row will be the average of the previous rows\n",
    "print(f'matrix a:\\n{a}')\n",
    "print(f'matrix b:\\n{b}')\n",
    "print(f'matrix c:\\n{c}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Self Attention V2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2\n",
    "# wei (short for weights) is the matrix we'll multiply our inputs with to get xbow\n",
    "wei = torch.tril(torch.ones(T, T)) # T, T because we want to mul with T, C to get T, C\n",
    "wei = wei / wei.sum(1, keepdim = True)\n",
    "wei"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.0613,  1.0447],\n         [-0.4936,  0.2141],\n         [-0.8303,  0.1645],\n         [-0.4739,  0.1569],\n         [-0.1582, -0.1843],\n         [-0.0348, -0.0981],\n         [ 0.1552, -0.1741],\n         [ 0.2458, -0.2741]],\n\n        [[ 1.6547,  0.5282],\n         [ 0.2378,  0.5293],\n         [ 0.3971,  0.9392],\n         [ 0.3010,  0.7072],\n         [ 0.2754,  0.6264],\n         [ 0.3268,  0.7056],\n         [ 0.1109,  0.5249],\n         [ 0.2850,  0.5235]],\n\n        [[ 1.0538,  0.1509],\n         [ 0.9856, -0.1346],\n         [ 0.4760,  0.4241],\n         [ 0.1226,  0.6300],\n         [-0.0399,  0.4964],\n         [ 0.1006,  0.6127],\n         [ 0.0724,  0.6003],\n         [-0.0534,  0.5590]],\n\n        [[ 1.1385,  0.4626],\n         [-0.0193, -0.1204],\n         [ 0.3171,  0.2542],\n         [ 0.2987,  0.1163],\n         [ 0.1737,  0.0299],\n         [ 0.3123, -0.1032],\n         [ 0.0927,  0.0549],\n         [ 0.1127,  0.2565]]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pytorch will perform a batched MatMul in parallel\n",
    "xbow2 = wei @ x # ((B), T, T) @ (B, T, C) -> (B, T, C) for each batch a T, T multiplies to a T, C\n",
    "xbow2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Self Attention V3\n",
    "\n",
    "We begin with wei being all zeros as a blank state to quantify how much of each token from the past do we want to aggregate. By performing the masked_fill operation we make sure that the tokens in the future aren't counted as they become zero when the softmax acts on them. Softmax converts all zeros to ones and -infs to zeros and then divides each row by the sum of the elements in that row. When we multiply this matrix to our input matrix we get our xbow."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.5064, -0.8704],\n         [-0.1404, -0.7553],\n         [-0.3181, -0.1281],\n         [-0.3003, -0.2513],\n         [ 0.1343, -0.1796],\n         [ 0.1141,  0.0509],\n         [ 0.2408,  0.1734],\n         [ 0.3410,  0.0985]],\n\n        [[ 0.7450,  0.3972],\n         [ 0.9023,  0.4240],\n         [ 0.0335,  0.4220],\n         [ 0.2682,  0.1206],\n         [ 0.2582, -0.0336],\n         [-0.0647, -0.0645],\n         [-0.1320,  0.0079],\n         [-0.1789, -0.0541]],\n\n        [[ 0.8481, -0.9877],\n         [ 0.7249, -1.1599],\n         [ 0.7210, -1.2412],\n         [ 1.1306, -1.2471],\n         [ 0.9891, -1.0831],\n         [ 0.9229, -0.6795],\n         [ 0.7867, -0.5523],\n         [ 0.6301, -0.5199]],\n\n        [[ 0.0439, -2.2378],\n         [ 0.3130, -1.9809],\n         [-0.5180, -1.3123],\n         [-0.5613, -1.0093],\n         [-0.3292, -0.9068],\n         [-0.1724, -0.7324],\n         [-0.1106, -0.7013],\n         [-0.0957, -0.5331]]])"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3 (using softmax)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros((T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "# perform a softmax across all elements in a row, i.e. convert 0 to 1 and -inf to 0\n",
    "# and then normalize the row, i.e. divide by the sum of the elements in the row\n",
    "wei = F.softmax(wei, dim=1)\n",
    "xbow3 = wei @ x\n",
    "\n",
    "xbow3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Self Attention V4\n",
    "Notice that `wei` has the same value for lower triangular elements in the same row. We don't want this to be uniform because different tokens find different tokens useful. This affinity should be data dependent. Self attention solves this problem by:\n",
    "\n",
    "Every single token emits two vectors `key` and `query`. The `query` vector signifies \"what am I looking for?\" and `key` vector signifies \"what do I contain?\". To get the affinities between the tokens in a sequence is by taking the dot product between `keys` and `queries`. The `query` of a token dot products with all the `keys` of the other tokens and that dot product becomes `wei` i.e. the affinities.\n",
    "\n",
    "This means that if the `key` and the `query` are aligned then they will interact more and their affinity for each other will be high in comparison to other tokens in the sequence.\n",
    "\n",
    "Note:\n",
    "This attention is called self attention because the keys, queries and the values, all come from the same source x.\n",
    "In encoder-decoder transformers we can have keys from x but queries and values can come from a different source. This is called cross attention where we have nodes from a separate source which we'd like to pool information from.\n",
    "\n",
    "### Questions\n",
    "1. What is the significance of `head_size`?\n",
    "2. Why use a Linear network to get head and value?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: tensor([[[ 2.5851e-01, -4.1287e-01, -3.4331e-01,  7.8676e-01,  5.9700e-01,\n",
      "          -1.9373e-01,  4.3467e-01,  7.6232e-01,  1.6628e-01, -1.0726e+00,\n",
      "           4.7617e-01, -2.1293e-01, -1.3552e-01, -2.3179e-01, -4.1144e-01,\n",
      "          -1.6659e-01],\n",
      "         [-1.1676e+00,  7.9744e-03, -4.3502e-02, -8.9976e-02, -1.1000e+00,\n",
      "          -1.0923e-01,  6.4384e-01, -4.8356e-02,  8.1363e-01,  4.7386e-01,\n",
      "           7.5937e-01, -1.8870e-01, -3.2153e-01,  5.1348e-01,  1.6355e-01,\n",
      "           6.3696e-01],\n",
      "         [ 1.2313e-01, -8.0748e-02, -1.0561e-01,  1.0522e-01, -1.8357e-01,\n",
      "          -4.5372e-01,  2.1923e-01,  6.7337e-01,  4.6693e-01,  1.5496e+00,\n",
      "           5.2441e-01,  8.6864e-01,  4.0643e-01, -8.4416e-01, -8.0568e-02,\n",
      "           7.1581e-01],\n",
      "         [ 2.7439e-01, -8.5302e-02,  3.0850e-01,  2.1752e-01, -2.8407e-01,\n",
      "           3.1418e-01, -5.2261e-01,  1.9404e-01, -2.0093e-01, -1.9599e-01,\n",
      "           6.4786e-02,  1.6166e-01, -7.1450e-01, -8.9573e-01, -3.8610e-01,\n",
      "           8.0427e-01],\n",
      "         [-7.4524e-02, -4.5285e-01,  3.6788e-01, -8.3774e-01, -1.3225e+00,\n",
      "          -3.4514e-02,  7.0508e-01, -4.0550e-01,  1.7868e-02,  1.0947e-01,\n",
      "           2.9388e-01,  5.4213e-01, -4.8531e-01, -1.4064e-01,  5.3257e-01,\n",
      "          -2.0118e-01],\n",
      "         [ 5.0508e-01,  2.7978e-01,  1.3798e-01,  1.8587e-01,  2.5696e-01,\n",
      "           3.3359e-01, -2.3672e-02,  3.4538e-01, -9.0902e-01,  5.3736e-01,\n",
      "          -9.8803e-02,  4.0375e-01,  5.2330e-01, -5.2289e-01,  1.1468e-01,\n",
      "           6.7759e-01],\n",
      "         [-8.3771e-01,  4.4684e-01, -8.7551e-02, -3.1386e-01,  6.7284e-01,\n",
      "           1.3402e-02, -9.0933e-01,  8.7207e-01,  5.0946e-01,  5.9306e-01,\n",
      "          -2.3023e-01,  7.3369e-02, -5.6639e-01,  1.7469e-01, -9.9996e-01,\n",
      "          -2.5840e-02],\n",
      "         [-2.9329e-01,  7.4945e-01,  2.4613e-01, -3.1081e-01,  5.0138e-01,\n",
      "           4.4750e-01, -3.6451e-01,  4.9409e-01,  1.9237e-01, -5.4309e-01,\n",
      "          -2.6778e-01, -8.4101e-01, -7.5252e-01,  2.3352e-01, -5.5805e-01,\n",
      "           1.4097e-01]],\n",
      "\n",
      "        [[-8.8867e-02, -7.7257e-02, -1.0252e-01,  2.2228e-01,  1.0821e+00,\n",
      "          -6.2021e-01, -5.4981e-01, -1.3893e-01, -8.9179e-01, -1.5178e-01,\n",
      "          -8.7779e-02,  1.3494e-02,  1.0198e+00,  8.5168e-01,  4.2620e-01,\n",
      "           5.1494e-02],\n",
      "         [ 4.7850e-01, -3.8472e-01, -3.7486e-01, -2.7250e-01,  3.9131e-01,\n",
      "          -8.3819e-02,  3.2446e-01, -1.0161e+00, -4.2272e-01,  3.4248e-01,\n",
      "           2.2230e-01,  1.5038e+00,  3.9495e-01, -9.4317e-01,  3.2202e-01,\n",
      "          -7.2004e-02],\n",
      "         [ 4.8077e-01,  3.7745e-02, -3.5355e-01, -5.2096e-02, -8.6071e-01,\n",
      "           1.7341e-01,  1.5804e-01, -8.9761e-01, -6.1193e-01, -2.2103e-01,\n",
      "           2.1779e-01,  3.8398e-01,  3.1030e-01,  9.1504e-01,  5.8280e-01,\n",
      "          -2.8976e-01],\n",
      "         [ 7.9990e-01, -5.8505e-01,  9.8298e-01,  8.7944e-02, -2.5510e-01,\n",
      "           1.1202e-03,  5.9403e-01, -3.3262e-01,  3.2807e-01, -2.9555e-01,\n",
      "          -3.0776e-01,  3.3217e-01,  6.0747e-01, -1.3959e+00, -8.7869e-01,\n",
      "          -2.6330e-01],\n",
      "         [ 9.0624e-01, -3.3163e-01, -6.4160e-01,  3.0219e-01,  9.1292e-01,\n",
      "           3.6042e-01,  2.5308e-01, -1.6221e+00,  6.0166e-01,  3.9576e-01,\n",
      "          -3.2160e-01,  1.1101e+00,  1.4856e+00, -1.7385e+00,  2.5428e-01,\n",
      "          -8.1483e-01],\n",
      "         [-2.2058e-01, -1.3505e-01, -1.5610e-01, -8.4095e-01,  5.1404e-01,\n",
      "          -1.7699e-01, -4.1736e-01,  1.1541e+00, -7.0983e-01,  6.2672e-01,\n",
      "          -6.1410e-01,  4.9517e-02, -3.1380e-01,  1.6919e-01, -3.4372e-01,\n",
      "           2.6023e-01],\n",
      "         [-4.3866e-01, -4.1158e-01, -8.3220e-01,  3.7559e-01,  6.7000e-01,\n",
      "          -2.8632e-01,  1.1760e+00,  4.4928e-02, -5.2680e-01, -1.0969e-01,\n",
      "           4.5236e-01,  5.9065e-01,  3.9270e-01,  7.9163e-01,  7.7930e-01,\n",
      "          -7.0952e-01],\n",
      "         [ 9.1085e-01,  1.2097e-01,  6.5139e-01,  4.5406e-01,  5.6373e-01,\n",
      "          -2.1949e-01, -8.3498e-01, -6.3548e-01,  6.3856e-01, -3.8237e-01,\n",
      "           2.9119e-01, -1.1649e-01,  2.1485e-01, -2.3665e-01,  2.5166e-01,\n",
      "          -6.0579e-01]],\n",
      "\n",
      "        [[-4.2660e-01, -5.1862e-02, -3.7566e-01,  9.6546e-02,  1.1695e+00,\n",
      "          -1.1528e+00, -2.7219e-01,  4.5229e-01,  5.6714e-03,  9.8665e-01,\n",
      "          -3.9210e-01,  3.7128e-02,  1.2072e+00,  7.3329e-01,  5.0789e-01,\n",
      "          -5.3883e-01],\n",
      "         [ 9.4569e-02,  3.2520e-01, -2.4122e-01, -1.9694e-01,  7.4770e-01,\n",
      "           1.1326e+00, -5.3305e-01, -3.1492e-01, -2.8351e-01, -2.1197e-01,\n",
      "          -4.1585e-01, -3.3854e-03,  7.1207e-02,  5.7514e-01, -1.8737e-01,\n",
      "          -1.0262e+00],\n",
      "         [ 3.7352e-01, -1.5291e+00,  8.4221e-02, -6.6923e-02, -3.6218e-01,\n",
      "           6.8278e-01,  2.6459e-01, -6.4971e-01, -4.3114e-01, -2.5331e-01,\n",
      "          -5.5992e-01,  1.0517e+00, -1.2252e-01,  8.8833e-01, -6.4152e-01,\n",
      "           1.7357e+00],\n",
      "         [-3.1844e-01,  7.9197e-01,  3.7884e-01, -2.6640e-01,  6.7020e-01,\n",
      "          -6.1054e-01, -1.6360e-01,  6.1377e-01, -2.3624e-02, -1.8346e-01,\n",
      "           4.2322e-01, -7.3302e-01, -7.0652e-01, -4.1943e-01,  2.3951e-01,\n",
      "          -3.2735e-02],\n",
      "         [-1.2649e-01,  8.4554e-01, -1.9661e-02,  1.8703e-01,  1.4021e+00,\n",
      "          -4.6417e-01,  7.7583e-01,  7.0786e-01,  5.9825e-01,  5.9307e-02,\n",
      "          -3.9773e-01, -4.5710e-01, -7.2517e-01, -5.9714e-01, -3.8620e-01,\n",
      "          -1.2356e-02],\n",
      "         [ 1.0206e-01, -1.0451e+00,  5.1534e-01,  1.3056e-01, -1.3576e-01,\n",
      "           1.3091e+00,  5.5679e-01, -3.5990e-01, -2.9512e-01, -1.6641e+00,\n",
      "          -2.1411e-01, -3.6010e-01,  1.7725e-01,  2.4512e-01, -4.2913e-01,\n",
      "           5.0998e-01],\n",
      "         [ 1.2468e+00,  3.0717e-01,  2.1565e-01,  2.0405e-01, -6.6994e-01,\n",
      "          -3.3786e-01, -2.3155e-01, -1.9900e-01, -2.9599e-01,  1.9823e-01,\n",
      "           5.4901e-01,  1.7116e-02,  6.6845e-01, -3.9877e-01, -6.4060e-02,\n",
      "           2.6647e-01],\n",
      "         [-1.0613e+00, -4.1797e-01, -2.1904e-01, -1.1843e-02,  1.8540e-01,\n",
      "          -9.0037e-02, -3.4654e-02,  3.6951e-01,  4.2855e-02,  1.2419e+00,\n",
      "          -5.6209e-01,  9.8762e-01,  4.6486e-01, -5.0335e-01, -1.5182e-01,\n",
      "           3.1604e-01]],\n",
      "\n",
      "        [[ 1.5762e-01, -4.8178e-01, -1.5253e-01, -2.0353e-01,  1.8694e-01,\n",
      "          -1.1331e-01, -4.6837e-01,  1.3358e+00, -1.9459e-01, -1.5897e-01,\n",
      "           4.5402e-01, -7.5939e-01, -4.2968e-01, -4.7905e-02,  5.2241e-01,\n",
      "          -8.3423e-01],\n",
      "         [-1.0928e+00,  4.8806e-02, -5.7477e-02,  4.0665e-01,  6.1965e-01,\n",
      "           1.1805e+00, -7.7353e-01,  8.2517e-01,  1.6485e-01,  3.0779e-02,\n",
      "          -9.8095e-01,  3.4000e-01, -3.5756e-01, -4.4144e-01, -3.7028e-01,\n",
      "          -7.2628e-02],\n",
      "         [-2.2966e-01,  1.7252e-01, -6.5254e-02, -1.0317e+00, -1.9704e+00,\n",
      "           2.4735e-01,  9.6875e-01, -2.8372e-01,  9.4487e-01, -2.7625e-02,\n",
      "           1.5230e+00,  3.1122e-01, -1.6632e+00,  9.5158e-02, -1.9037e-01,\n",
      "           8.3347e-02],\n",
      "         [-2.6760e-01, -1.4392e-01,  2.1259e-01, -2.4228e-01, -7.3718e-01,\n",
      "           1.9127e-01, -2.6759e-01, -1.1117e+00,  2.9346e-02, -3.7409e-01,\n",
      "           1.4925e-01, -3.6768e-01, -8.1590e-01,  8.1816e-01, -3.0574e-02,\n",
      "           1.0367e+00],\n",
      "         [ 4.0571e-02, -3.2723e-01, -1.9983e-01, -9.0989e-01, -4.6227e-01,\n",
      "           4.1687e-01,  3.6946e-01,  5.9140e-01,  2.6984e-01,  8.7724e-02,\n",
      "           7.4062e-01,  5.9996e-01, -4.5029e-01,  2.7402e-02, -3.5514e-01,\n",
      "           4.7167e-01],\n",
      "         [-2.3266e-01,  4.3766e-01, -4.8744e-01, -1.9211e-01,  2.4236e-01,\n",
      "          -6.1620e-01, -7.4713e-01,  3.6315e-01,  1.3997e-01,  1.1360e+00,\n",
      "          -8.6016e-02, -1.0704e+00,  6.6024e-01, -4.5859e-01,  7.3640e-03,\n",
      "          -6.2095e-01],\n",
      "         [-9.0585e-01, -4.1221e-01,  5.1276e-01,  3.3547e-02, -1.3055e+00,\n",
      "           1.4456e+00,  1.2773e-01,  1.3965e-01,  5.6041e-01, -9.6240e-02,\n",
      "          -6.1129e-01,  4.9094e-01,  1.0696e-01,  5.7004e-01, -6.6978e-01,\n",
      "           8.6646e-02],\n",
      "         [ 1.2927e-01,  1.9122e+00,  6.8127e-01, -4.0336e-01, -1.5703e+00,\n",
      "          -4.4180e-01,  7.0271e-01,  7.9762e-02,  3.0444e-01,  1.2124e+00,\n",
      "          -3.3036e-01,  6.5626e-01,  1.5268e-01,  7.3629e-01,  1.1427e+00,\n",
      "          -5.4300e-01]]], grad_fn=<UnsafeViewBackward0>)\n",
      "query: tensor([[[ 0.4665,  0.6389, -0.3167,  1.0280,  0.2170,  0.3074, -0.1343,\n",
      "          -0.7622,  0.7830, -0.5999, -0.0440,  0.2827,  0.5158, -0.4737,\n",
      "           0.5017, -0.4872],\n",
      "         [-0.8296,  0.4951, -0.6535, -0.5816,  0.8831, -0.2922,  0.3022,\n",
      "           0.6711, -0.8552,  0.7522, -0.5581,  0.2841, -0.4638,  0.1102,\n",
      "          -0.6154,  1.5737],\n",
      "         [-0.1849, -0.0655, -1.2114, -0.3389, -0.5342,  0.0415, -1.3727,\n",
      "          -0.0833,  0.1481, -0.5898, -0.2167,  0.3892,  1.0128,  0.6113,\n",
      "          -0.1721,  0.2104],\n",
      "         [ 0.4980, -0.9514, -0.1804, -0.1901, -0.6710, -0.9219,  0.3192,\n",
      "          -0.7009,  0.1451,  0.6158,  0.2775,  0.0185, -0.4462,  0.4594,\n",
      "          -0.1171, -0.0967],\n",
      "         [-0.5373, -0.6220,  0.2363, -1.2961, -0.1614, -0.6758,  0.9051,\n",
      "           0.2126, -0.2581, -0.4152,  0.1684,  0.1741,  0.2907, -0.4509,\n",
      "           0.1483,  0.3065],\n",
      "         [ 0.0226,  0.9978, -0.7026, -0.3086, -0.1524, -1.3488, -0.2320,\n",
      "           0.0197,  1.1594,  0.2127,  0.9818,  0.5355, -0.0916, -0.2309,\n",
      "          -0.3877, -0.0473],\n",
      "         [ 0.5332,  0.4277, -0.5926,  0.3767, -0.6562, -0.1768, -0.0722,\n",
      "           0.7555,  0.0983, -0.1501,  0.5721, -0.2778, -0.6248, -0.2973,\n",
      "          -0.2729, -0.2443],\n",
      "         [ 0.0989, -0.3122,  0.2688, -0.2041,  1.5787, -0.1273, -0.3928,\n",
      "          -1.0669,  0.6311,  0.4249,  0.0942,  0.7475, -0.5822,  1.0189,\n",
      "          -0.1063, -0.1535]],\n",
      "\n",
      "        [[ 1.1827, -0.5587, -0.1522,  1.1922, -0.2378,  0.1498,  0.9617,\n",
      "           0.0860, -0.0677, -0.5593, -0.1784,  0.1835, -0.6599, -0.0332,\n",
      "          -0.1535, -0.3816],\n",
      "         [ 0.2814, -0.5098, -0.5139, -0.1799, -0.2523,  0.1681,  0.5849,\n",
      "          -0.1549,  0.6212, -0.9533,  0.7237,  0.4625, -0.0903, -0.1218,\n",
      "          -0.0323, -0.5945],\n",
      "         [ 0.0832, -0.5738,  0.4571, -0.5419, -0.2152,  0.4852,  1.2599,\n",
      "           0.1854, -0.3358,  0.1322,  0.6059,  0.1202,  0.1075, -0.2300,\n",
      "           0.3503, -0.0560],\n",
      "         [ 0.4180,  0.1295, -0.1663,  0.1948, -0.0516,  0.5734,  0.1317,\n",
      "           0.6218,  0.5658, -0.4936, -0.4339, -0.8190, -0.0964,  0.2211,\n",
      "          -0.5225, -0.7480],\n",
      "         [-0.7296, -0.0034,  0.7523, -0.7615,  0.1420,  0.8994, -0.0972,\n",
      "           0.0688,  0.9189, -0.2857,  0.3186, -0.0829,  0.2006,  0.2117,\n",
      "           0.5111, -0.4509],\n",
      "         [-0.2455,  0.5957,  0.7527,  0.1491, -0.1036, -0.0885, -0.3963,\n",
      "          -0.1066,  0.2930,  0.1032,  0.0789,  0.2435, -0.8300,  0.7171,\n",
      "          -0.5524, -0.2361],\n",
      "         [-0.5192,  0.9681,  0.2625,  0.2605, -0.4708,  0.4887,  0.0758,\n",
      "           0.2190, -0.5526,  0.1284, -0.6253,  0.8836,  1.0615, -0.7843,\n",
      "           0.4296,  0.2825],\n",
      "         [ 0.1693,  0.0362, -0.2856, -0.6432, -0.5408,  0.2206,  0.6202,\n",
      "           0.3758,  0.4650,  0.5946,  0.9323, -1.9557, -0.1686, -0.5452,\n",
      "          -0.3109,  0.6726]],\n",
      "\n",
      "        [[-0.0826,  1.2161, -0.0532, -0.5688,  0.9405, -0.2443,  0.4557,\n",
      "          -0.2385,  0.2778, -0.5875,  0.2079, -0.8142, -0.0848,  0.2081,\n",
      "          -0.9497,  0.3487],\n",
      "         [ 0.0031, -0.3090, -0.1533, -0.4023, -0.1358, -0.0212, -0.1086,\n",
      "          -0.2475, -0.0773, -0.1661, -0.2299, -0.4687, -0.0073,  0.2321,\n",
      "           0.7902,  0.2221],\n",
      "         [-2.0048,  0.8922,  0.1725, -0.4478,  0.6309, -0.2326, -1.4735,\n",
      "          -0.2634, -0.0800, -0.2045,  0.2715, -0.0669, -0.5063,  0.1296,\n",
      "          -1.1330,  1.6489],\n",
      "         [ 0.2263, -0.1388, -0.2402,  0.1414, -0.4239, -0.5762, -0.5675,\n",
      "           0.0808,  0.1713,  0.5508,  0.0757,  0.5158,  0.1289, -0.3763,\n",
      "          -0.3383, -0.4739],\n",
      "         [-0.0719,  0.9822,  0.5289,  0.0359,  1.3820,  0.2091, -0.0875,\n",
      "           0.0252,  0.7118,  0.8205,  0.2378,  0.7296,  0.0760,  0.9845,\n",
      "          -0.3791, -1.4417],\n",
      "         [ 0.3370, -0.5001,  0.2555,  1.0792,  0.1625, -0.5712,  0.1997,\n",
      "          -0.1718,  0.2459,  0.6928, -0.4255,  1.3396, -1.4384, -0.4908,\n",
      "           0.1171,  0.4494],\n",
      "         [ 0.5851, -0.0569, -0.5291, -0.2186, -0.3272, -0.0371,  0.7211,\n",
      "           0.2374,  0.9304,  0.3581,  0.3559,  0.0413,  0.6994, -0.3532,\n",
      "           0.1809,  0.0155],\n",
      "         [ 0.2131,  0.1266,  0.1860, -0.8942,  0.5564, -0.1710, -0.0106,\n",
      "          -0.3983, -0.1496, -1.1399, -0.7215,  0.4794,  0.5070,  0.2567,\n",
      "           0.2510, -0.4024]],\n",
      "\n",
      "        [[ 0.6195,  0.2735,  0.5285,  0.8169, -0.7064, -0.0941,  0.2548,\n",
      "           0.3166,  0.8124,  0.8064, -0.5763, -0.0837, -1.3237, -0.2126,\n",
      "           0.5246,  0.2589],\n",
      "         [ 0.7386, -0.1848,  0.1649, -0.1665, -0.2816, -0.7196,  0.9414,\n",
      "          -0.6341, -0.0897, -0.4190, -0.4655, -0.3785, -0.4902,  0.1446,\n",
      "           0.5279, -0.1566],\n",
      "         [-0.1156,  0.0341, -0.9475, -0.1721,  0.4588,  0.2560,  0.5011,\n",
      "           0.6185,  0.2445,  0.3150,  0.2574,  1.2358,  0.2415, -0.9659,\n",
      "           0.3581,  0.5515],\n",
      "         [-1.6167,  0.2783,  0.0483, -1.4549,  1.8873, -0.6152, -0.3107,\n",
      "           0.0804, -0.4150,  0.0766, -0.1319,  0.6349,  0.0168,  0.3351,\n",
      "           0.0057,  0.5092],\n",
      "         [-0.2775,  0.8624, -0.4752,  0.4226, -0.0193,  0.5525, -0.5003,\n",
      "          -0.3917, -0.0889, -0.4458,  0.3243,  0.5240,  0.4714, -0.4181,\n",
      "          -0.2507, -0.3350],\n",
      "         [-0.4898,  0.7418,  1.1163, -0.4986,  0.2202,  0.4142, -0.8892,\n",
      "           0.4079,  0.0131,  1.0550, -0.5947,  0.1937,  0.5337,  0.3338,\n",
      "           0.2453, -0.2444],\n",
      "         [-0.2644, -0.2848, -0.6540, -0.6195, -0.2175, -0.3383, -0.1351,\n",
      "          -0.0652,  0.2480, -0.0491,  0.4037,  0.4568, -0.5123, -0.7818,\n",
      "          -0.2154,  1.7412],\n",
      "         [-0.6377, -0.9445, -1.1297, -1.5284, -0.4694,  0.0807,  1.3916,\n",
      "           0.3527,  0.2241,  0.4492,  0.7126, -0.5150,  1.2653,  0.0098,\n",
      "          -0.8349,  1.2146]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "key_shape: torch.Size([4, 8, 16])\n",
      "query_shape: torch.Size([4, 8, 16])\n",
      "\n",
      "out: tensor([[[-1.3590e-02, -8.3476e-03, -1.3524e-02,  3.1779e-02,  1.4636e-02,\n",
      "           7.9277e-02, -3.7815e-02, -1.2752e-02, -1.1312e-01,  4.5082e-02,\n",
      "           7.5100e-02,  9.2492e-02,  1.1015e-02, -3.4737e-03,  6.4492e-03,\n",
      "           4.3065e-02],\n",
      "         [-2.8671e-02, -3.5201e-02, -7.2336e-02, -2.7764e-02, -6.4755e-02,\n",
      "          -3.9350e-02, -1.4727e-01, -1.0558e-01, -1.1316e-01,  1.6770e-01,\n",
      "           1.2741e-01, -4.6862e-03, -3.7303e-02, -8.2918e-03, -1.1922e-01,\n",
      "           4.0292e-02],\n",
      "         [-1.5315e-01, -2.0023e-01, -5.1239e-02,  9.7818e-02, -9.0200e-02,\n",
      "          -3.8364e-02, -7.3194e-02, -1.0127e-02, -9.9452e-02,  1.6330e-01,\n",
      "           6.2587e-02,  1.1468e-01, -3.9892e-02,  5.5970e-02, -2.7909e-02,\n",
      "          -3.4883e-03],\n",
      "         [-2.8504e-01, -4.3051e-01, -2.3706e-01,  1.3713e-01,  6.2826e-02,\n",
      "           1.3015e-01,  1.0587e-02, -5.6694e-02, -1.2928e-01,  1.3375e-01,\n",
      "           1.0765e-01,  9.8915e-02, -1.2316e-01,  1.5207e-01, -2.8065e-03,\n",
      "          -5.9096e-02],\n",
      "         [-2.3370e-01,  4.2916e-02, -2.8823e-02,  8.6342e-02, -5.3141e-02,\n",
      "           7.2682e-02, -1.0566e-02, -4.9252e-01, -7.2801e-02,  1.9171e-01,\n",
      "           2.9190e-01, -3.2952e-01, -3.4482e-01, -3.9821e-01, -3.6116e-02,\n",
      "           2.9556e-02],\n",
      "         [-4.8418e-01, -3.0847e-01, -3.4341e-01,  2.7070e-01, -5.0475e-02,\n",
      "           3.8122e-01, -1.5808e-01, -4.7338e-01, -2.3137e-02,  1.6683e-01,\n",
      "           4.3811e-01,  2.2236e-01, -3.1572e-01,  2.4103e-01, -1.4095e-01,\n",
      "           3.4566e-02],\n",
      "         [-9.3678e-02, -3.1159e-01, -6.1664e-01,  4.6030e-01, -3.7158e-01,\n",
      "           6.9980e-01,  4.6271e-02, -2.4148e-01,  1.6149e-02, -1.2720e-02,\n",
      "           6.3695e-01,  2.8821e-01, -2.0659e-01,  1.7053e-01, -2.6864e-01,\n",
      "           2.7816e-01],\n",
      "         [-4.1996e-01,  2.8977e-01, -5.9190e-01,  9.8418e-02, -1.2292e+00,\n",
      "           6.9792e-01, -2.8811e-01,  6.2979e-02, -1.0692e-01, -4.8207e-01,\n",
      "          -4.6053e-01,  1.9420e-01, -8.3286e-01,  9.3007e-02, -7.5897e-01,\n",
      "          -1.5515e-01]],\n",
      "\n",
      "        [[ 7.6876e-02,  2.6833e-02,  8.2124e-02,  5.3994e-02, -6.4984e-02,\n",
      "           1.1039e-01, -1.3479e-01,  3.2040e-02, -7.9116e-02,  2.4063e-02,\n",
      "          -4.2448e-03,  3.3150e-02, -4.3066e-02,  1.7213e-01, -4.5876e-03,\n",
      "           1.0557e-01],\n",
      "         [-7.0333e-03, -4.0764e-02,  5.6751e-02,  2.1326e-01,  2.9011e-02,\n",
      "           3.2626e-01, -3.0147e-01, -4.1311e-02, -1.3212e-01,  6.9888e-02,\n",
      "           2.3061e-01,  1.5099e-01, -1.5564e-01,  2.9542e-01,  1.0596e-01,\n",
      "           1.0654e-01],\n",
      "         [ 1.8568e-01,  8.4190e-02,  1.4673e-01,  2.5069e-01,  2.3537e-01,\n",
      "           3.8201e-01, -3.7747e-01, -1.8413e-01, -3.4735e-01,  1.1782e-01,\n",
      "           1.9881e-01,  1.3022e-01, -2.4905e-01,  3.0391e-01,  1.9201e-01,\n",
      "           8.2218e-02],\n",
      "         [ 3.0682e-01,  9.0224e-02,  1.2472e-01,  1.7138e-01,  5.7319e-02,\n",
      "           1.6486e-01, -3.3706e-01,  1.3802e-02, -1.9665e-01,  1.6311e-01,\n",
      "           1.2230e-01,  7.9871e-02, -4.0796e-02,  5.9766e-02,  8.9289e-02,\n",
      "           1.7363e-01],\n",
      "         [ 2.6898e-02, -2.1578e-02,  1.6093e-01,  2.6856e-01,  1.9926e-01,\n",
      "           2.7631e-01, -2.1770e-01,  2.1140e-02, -7.3150e-03,  3.8309e-01,\n",
      "           2.8107e-01,  4.3387e-01, -3.1215e-01, -1.3606e-01,  3.4399e-01,\n",
      "           1.0846e-01],\n",
      "         [ 8.4952e-02,  4.1147e-01,  1.6934e-01,  3.8192e-02,  1.0701e-01,\n",
      "           4.7426e-01, -1.5064e-01,  2.6971e-01,  4.7543e-02,  7.9999e-02,\n",
      "           1.0650e-02,  3.0270e-01, -3.0248e-01, -2.0969e-01, -4.9409e-02,\n",
      "          -1.0040e-01],\n",
      "         [-1.1777e-01,  5.1857e-01,  1.2773e+00,  5.8502e-02,  4.2568e-01,\n",
      "           3.7892e-01,  2.1631e-01,  3.4586e-01,  2.4780e-01,  6.4341e-01,\n",
      "           4.6060e-01,  1.0762e+00, -9.1843e-01, -9.2096e-01,  3.7313e-01,\n",
      "           2.2641e-01],\n",
      "         [ 1.1292e-01, -2.3668e-01,  1.1707e+00, -4.8624e-01,  6.0341e-01,\n",
      "          -3.0354e-01,  9.7342e-01, -5.9441e-01,  5.9864e-01,  6.7931e-01,\n",
      "           4.0381e-01,  9.9615e-01,  3.9174e-01, -1.2658e+00,  1.4281e-01,\n",
      "          -5.7409e-01]],\n",
      "\n",
      "        [[-2.1994e-02,  5.4579e-02,  2.4130e-02, -8.7790e-02, -1.1580e-02,\n",
      "           3.2686e-02, -6.6435e-02, -1.9931e-02, -5.7853e-03,  5.9784e-02,\n",
      "           3.6600e-02,  1.3803e-01, -2.2403e-02, -7.0894e-03, -7.0045e-02,\n",
      "          -2.3470e-02],\n",
      "         [ 2.2970e-02, -7.4268e-03,  7.0930e-02, -6.5452e-02, -4.6946e-02,\n",
      "          -8.2929e-02,  1.0501e-01, -1.9549e-02,  7.2563e-02, -9.2423e-02,\n",
      "          -1.2420e-01,  1.4698e-01,  4.3022e-02,  6.4321e-02, -1.5407e-01,\n",
      "          -3.5749e-02],\n",
      "         [-1.4636e-01,  1.8368e-01,  5.8490e-02, -1.1071e-01, -6.7551e-03,\n",
      "          -1.6528e-01,  1.1197e-01, -6.6402e-02,  3.8121e-01,  6.7424e-02,\n",
      "           1.0985e-01,  1.7842e-01,  5.9934e-02, -1.3868e-01, -1.3528e-01,\n",
      "          -2.9385e-02],\n",
      "         [-1.0754e-01,  8.4872e-02,  8.3083e-02, -1.5018e-01, -1.3093e-02,\n",
      "          -7.9076e-02,  1.1020e-01, -6.3455e-02,  3.1973e-01, -3.3847e-02,\n",
      "           9.0295e-02,  1.2050e-01,  1.4268e-01, -8.0535e-02, -2.4308e-01,\n",
      "           1.2734e-02],\n",
      "         [-1.0457e-01,  1.3616e-01,  1.8355e-01, -1.6306e-01, -1.1112e-01,\n",
      "          -1.0117e-01,  2.1002e-01,  2.4782e-01,  1.2752e-01, -4.2955e-01,\n",
      "          -4.5746e-01,  5.5752e-01,  1.9409e-01, -1.4332e-01, -2.8778e-01,\n",
      "          -2.4889e-01],\n",
      "         [-2.5548e-01,  5.5207e-01, -3.6831e-02, -6.1379e-02, -2.0850e-01,\n",
      "          -4.6816e-02, -2.5854e-01, -7.1829e-02,  3.8357e-01,  1.5078e-01,\n",
      "          -3.2373e-02,  2.2168e-01, -4.6274e-02, -1.5842e-01, -2.0093e-01,\n",
      "           1.6481e-01],\n",
      "         [ 7.4887e-02,  1.6274e-02,  1.2896e-01,  2.7185e-02, -1.3365e-01,\n",
      "           3.6530e-01, -6.0626e-01, -5.3137e-01, -1.5986e-01,  1.0359e-01,\n",
      "          -2.6783e-01,  2.5243e-01,  1.1918e-01, -6.9059e-02, -8.7141e-02,\n",
      "           5.1870e-02],\n",
      "         [-3.7228e-01,  4.8809e-01,  5.5463e-01, -7.4788e-01, -4.9614e-01,\n",
      "           7.4279e-01, -1.1173e+00,  7.0763e-02,  7.6592e-02,  7.0484e-01,\n",
      "          -1.4121e-01,  6.6638e-01, -1.0084e+00,  5.3079e-01, -3.5027e-01,\n",
      "           2.3944e-01]],\n",
      "\n",
      "        [[ 5.2541e-02, -3.6870e-03,  2.7662e-02,  3.4109e-05,  6.2053e-02,\n",
      "           1.3195e-01,  3.8415e-02, -4.1036e-02, -5.1678e-02, -5.2359e-02,\n",
      "          -1.1783e-01, -3.1720e-02,  5.9841e-03,  1.0549e-02, -2.5258e-01,\n",
      "           4.2177e-02],\n",
      "         [ 6.2483e-02, -1.8625e-03, -9.3824e-03, -7.0681e-02,  6.2527e-02,\n",
      "           1.7776e-01,  5.5757e-02,  1.9166e-03, -4.3139e-02, -6.2374e-02,\n",
      "          -1.1499e-01, -1.5486e-02, -2.6983e-02,  4.3571e-02, -2.5891e-01,\n",
      "           4.1429e-02],\n",
      "         [ 1.3070e-01, -3.4146e-03, -3.4633e-02, -9.3827e-02, -1.6747e-02,\n",
      "           2.1255e-01, -7.0950e-02, -8.7798e-02, -2.3889e-01, -1.1170e-01,\n",
      "          -5.2068e-02, -1.7825e-01, -1.1626e-01, -2.9097e-03, -2.6080e-01,\n",
      "           8.4273e-02],\n",
      "         [ 1.1841e-01,  2.4283e-01, -6.7364e-02, -1.5550e-02, -6.3812e-02,\n",
      "           1.8744e-01,  4.0588e-02, -1.8012e-01, -1.3243e-01, -1.8436e-01,\n",
      "          -1.4211e-01, -1.6351e-01, -4.4716e-02, -2.6196e-02, -3.2360e-01,\n",
      "           5.3617e-02],\n",
      "         [ 7.6301e-02,  1.9736e-01, -7.3519e-02, -1.2791e-02,  5.4015e-02,\n",
      "           3.6962e-02,  7.4257e-02, -2.4849e-01, -3.1237e-01, -2.6932e-01,\n",
      "          -1.2076e-02, -1.7022e-01, -9.6626e-03,  6.0999e-02, -2.0705e-01,\n",
      "           3.4103e-02],\n",
      "         [-1.6776e-01,  1.6864e-01,  2.4457e-01, -3.2982e-01,  1.4337e-01,\n",
      "          -1.1455e-01,  6.8622e-01,  2.0877e-01,  2.4547e-02, -6.2963e-01,\n",
      "          -5.5238e-01, -6.9770e-02, -1.1795e-01, -5.2062e-01, -4.9846e-01,\n",
      "          -3.3541e-01],\n",
      "         [-1.5260e-01,  6.8812e-01,  3.2470e-02, -2.1308e-02, -5.2203e-01,\n",
      "          -5.6227e-01, -2.0230e-01, -7.2471e-01, -3.1997e-01, -4.0254e-02,\n",
      "           6.9100e-02, -5.6262e-01, -5.2670e-01, -5.3691e-01, -4.4654e-01,\n",
      "           1.6329e-01],\n",
      "         [-5.2245e-01,  4.4538e-01,  1.5243e-01, -1.4536e+00, -6.9043e-01,\n",
      "          -1.3667e+00, -7.2830e-01, -1.2465e+00, -2.5391e-01,  2.3229e-02,\n",
      "           1.0186e-01, -1.2382e+00, -8.3888e-01, -1.5788e+00, -2.6020e-01,\n",
      "          -4.5262e-01]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "out_shape: torch.Size([4, 8, 16])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# create a single head of self attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False) # v is what x communicates, the value that is passed for aggregation\n",
    "\n",
    "# all tokens produce a key and a query in parallel\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "v = value(x)\n",
    "\n",
    "# transpose last two dimensions to multiply\n",
    "# (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "# when all the queries dot product with all the keys, communication happens\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5 # multiply with sqrt of head_size to bring down variance to order of 1\n",
    "\n",
    "print(f'key: {k}\\nquery: {q}\\n')\n",
    "print(f'key_shape: {k.shape}\\nquery_shape: {q.shape}\\n')\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# we have implemented a decoder block\n",
    "# to make it an encoder block we simply remove this line\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "out = wei @ v\n",
    "\n",
    "print(f'out: {out}\\n')\n",
    "print(f'out_shape: {out.shape}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.1509, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1041, 0.1390, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1052, 0.1119, 0.1155, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1041, 0.1725, 0.1721, 0.1845, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1234, 0.1602, 0.1658, 0.1935, 0.3870, 0.0000, 0.0000, 0.0000],\n        [0.1304, 0.1850, 0.2660, 0.1928, 0.2238, 0.3054, 0.0000, 0.0000],\n        [0.1776, 0.1325, 0.1601, 0.2673, 0.2169, 0.3796, 0.4267, 0.0000],\n        [0.1042, 0.0989, 0.1205, 0.1618, 0.1723, 0.3150, 0.5733, 1.0000]],\n       grad_fn=<SelectBackward0>)"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first random batch:\n",
      "tensor([[ 1.1596, -1.0325,  0.5718, -0.5659, -1.1066, -1.1276,  1.0541, -0.7281,\n",
      "          0.4765,  0.5276,  1.3571,  0.5979, -0.5872, -0.3202, -0.4962,  1.2043,\n",
      "          1.5086, -1.5002,  2.3669,  1.5391,  0.0814, -0.0291,  1.0651, -1.0877,\n",
      "          0.3377, -0.1240,  0.2149, -0.0827, -0.3799, -0.1128, -0.9547,  0.2862],\n",
      "        [ 0.7990,  2.1681,  0.5425, -0.2722, -0.5659,  0.8444, -0.3682, -0.1785,\n",
      "         -0.2294,  0.0187, -0.7815, -0.5654, -0.1671,  0.7232,  0.9447,  1.0631,\n",
      "          1.0371,  0.0221,  1.6805, -0.7907,  1.2298, -0.2323,  0.2118,  1.0211,\n",
      "          0.0134, -0.8806,  0.5978,  0.0731,  0.4269,  1.7898,  0.9360, -0.6859],\n",
      "        [ 0.3657, -0.1974, -1.0244,  0.2563, -0.4931,  0.1098, -1.8298, -0.2591,\n",
      "          0.1388, -1.2638, -0.4718, -0.7666, -0.0617,  0.4684,  0.3686, -1.5033,\n",
      "         -0.2658, -0.3045,  0.1504,  0.6511, -0.6238,  0.5750, -0.0661, -0.3766,\n",
      "         -1.5509,  2.1236, -0.2280,  1.7334, -0.7190,  0.4774, -0.6639,  0.7482],\n",
      "        [-0.7582,  0.5024, -0.0981, -1.7422, -0.6895,  0.2569, -1.1723, -0.6761,\n",
      "         -0.5738, -0.2968, -0.4716, -0.1693, -2.1625, -0.0272, -1.3077, -0.0882,\n",
      "          1.0611,  0.2133,  0.6341,  0.9043, -2.2882,  0.5642,  0.3763,  0.7898,\n",
      "          1.6196,  0.2135, -1.2345, -0.5366,  0.8189, -1.1815,  1.2348, -1.1571],\n",
      "        [ 2.7875, -0.0557,  1.8434,  0.0562, -0.5491, -0.5360,  0.1249, -0.1836,\n",
      "         -1.6194,  0.9395, -1.3099, -0.0106,  0.1396, -0.9100, -0.1003,  2.1676,\n",
      "          0.1695, -0.1421, -1.3509,  0.1282,  1.2817, -0.1072,  0.6471, -0.3090,\n",
      "         -0.0887,  1.5492, -2.6243, -0.5194,  1.0821,  1.1809,  0.8313, -1.2919],\n",
      "        [ 0.4285,  1.2067,  0.6162,  1.0248,  0.6670,  1.2144, -1.3426,  1.6934,\n",
      "         -2.1583, -1.3384,  0.4890,  0.8552, -0.8102, -0.7665, -1.1086,  0.3350,\n",
      "          0.3741, -1.2231,  2.0092, -0.2357, -1.1904,  1.6277, -1.5983, -0.3943,\n",
      "         -1.1345,  0.3554,  0.4885,  1.1295, -0.4265, -0.7941, -1.5070,  0.3958],\n",
      "        [ 0.0426, -0.9410, -1.2465,  0.0682, -0.7628, -0.1140, -0.2339, -1.4984,\n",
      "          0.1806, -0.8450, -1.5250,  0.4154, -2.6643,  0.3240,  0.0234,  0.5138,\n",
      "         -0.0119,  1.6658,  0.4757,  1.3233,  0.9784,  0.3283,  1.2239, -0.8761,\n",
      "         -0.9378,  0.6470, -1.1316,  0.4184, -0.0604, -1.1328,  0.4973, -0.4053],\n",
      "        [-0.6813,  0.1286,  1.6292,  0.1272, -0.5054, -1.1733, -1.4061, -0.9937,\n",
      "         -0.3372,  2.6139, -0.1118,  1.9329, -0.7597, -0.0933,  0.2599, -0.2153,\n",
      "         -1.0887,  0.4714,  0.2625,  1.1944,  0.6801, -0.8606,  0.7562, -0.7030,\n",
      "         -1.3007,  1.8792,  0.3689,  0.4594,  0.4344, -0.6305,  1.3832,  0.7070]])\n",
      "\n",
      "keys for x:\n",
      "tensor([[ 0.5596, -0.0802, -0.0740,  0.2397, -0.7679,  1.4969, -1.4329,  0.3024,\n",
      "          1.0584, -0.8204, -1.2609,  0.2077,  0.1036, -0.0440, -0.2670,  0.3586],\n",
      "        [-0.9606, -0.6170, -0.2638, -0.7087,  0.3975,  0.1942, -0.0277,  0.4891,\n",
      "         -0.6372, -0.6271, -0.5176,  0.5948,  0.5322, -0.9183, -0.8345,  0.1201],\n",
      "        [ 0.4878,  0.1572,  0.2911,  0.3517, -0.3962, -0.3003,  0.3190, -0.3067,\n",
      "         -0.4200, -0.2212, -0.2019,  0.3881,  0.0185,  0.2928, -0.1221, -1.1589],\n",
      "        [-0.0027, -0.5180, -1.0149,  0.9513,  0.3721,  0.7333, -0.7737,  0.4788,\n",
      "          0.0512, -0.1904, -0.1207,  0.8436,  0.3644,  1.0981, -0.3252, -0.1116],\n",
      "        [-1.6216,  1.0207, -0.9661, -0.7381, -0.7037,  0.5808, -0.9146,  0.1989,\n",
      "          0.4243, -0.9345, -0.0041, -1.1069, -0.1686,  0.7350, -0.0228, -0.5829],\n",
      "        [ 1.2430,  0.1867, -0.3285,  0.4154,  1.4585,  0.6847,  0.0364,  0.0731,\n",
      "         -0.4519, -1.2077, -1.0137, -0.0549, -0.3543, -0.2183, -0.5710,  0.4115],\n",
      "        [ 0.6552,  0.4439, -0.0960,  0.8371, -0.8917, -0.2260, -1.2894, -0.0277,\n",
      "         -0.1410,  0.1647, -0.1735,  0.0558,  0.9198,  0.7128, -0.2547, -0.3291],\n",
      "        [-0.2219,  0.6390,  0.3652,  0.7071, -0.5698, -0.5758,  0.0905, -0.3459,\n",
      "         -0.3731, -0.0659, -0.0321, -0.1500,  0.0769,  0.5905,  0.2611, -0.3490]],\n",
      "       grad_fn=<MmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "first_random_batch = x[0]\n",
    "print(f'first random batch:\\n{first_random_batch}\\n')\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "keys = key(first_random_batch)\n",
    "print(f'keys for x:\\n{keys}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Multi Head Attention\n",
    "We can apply multiple attentions in parallel and concatenate their results."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
