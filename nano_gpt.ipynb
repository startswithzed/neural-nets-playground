{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "!pip install -Uqq torch\n",
    "!pip install -Uqq numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Raw Implementation Of GPT Like Model\n",
    "### Download The Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-08 12:25:10--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1115394 (1.1M) [text/plain]\r\n",
      "Saving to: ‘input.txt’\r\n",
      "\r\n",
      "input.txt           100%[===================>]   1.06M  1.79MB/s    in 0.6s    \r\n",
      "\r\n",
      "2023-03-08 12:25:12 (1.79 MB/s) - ‘input.txt’ saved [1115394/1115394]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open('data/tinyshakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect The Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "1115394"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first 1000 characters\n",
    "print(text[:1000])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get The Vocabulary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    },
    {
     "data": {
      "text/plain": "65"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get set of all chars in the text and then get that as a sorted list\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "vocab_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenize The Input\n",
    "Since this is a character level language model, we'll just translate individual characters to integers.\n",
    "\n",
    "Other tokenizers to look into:\n",
    "1. SentencePiece (Google)\n",
    "2. Tiktoken (OpenAI)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42, 2]\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # take a string and output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # take a list of integers and output a string\n",
    "\n",
    "print(encode(\"Hello World!\"))\n",
    "print(decode(encode(\"Hello World!\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stoi is a lookup table where key is the index and value is the character\n",
    "type(stoi)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "# encode the dataset and get a tensor\n",
    "# data type is int16 because our vocab size is only 65\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Training and Validation Splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(1003854, 111540)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(0.9*len(data)) # split 90% of data\n",
    "train_data = data[:n] # first 90% is training data\n",
    "val_data = data[n:] # rest is validation data\n",
    "\n",
    "len(train_data), len(val_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Batches Of Data To Train The Model\n",
    "\n",
    "Sample random chunks of data from the training set. These chunks are of fixed max length.\n",
    "In a chunk of 9 characters like `[18, 47, 56, 57, 58,  1, 15, 47, 58]` there are 8 examples for the model to train itself on like:\n",
    "1. In the context of 18, 47 likely comes next.\n",
    "2. In the context of 18 and 47, 56 likely comes next and so on.\n",
    "\n",
    "This also helps the transformer network get used to seeing context length of 1 character upto the max context length."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 # max length of chunks\n",
    "train_data[:block_size + 1] # first 9 chars in the training set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([18])\ttarget: 47\n",
      "input: tensor([18, 47])\ttarget: 56\n",
      "input: tensor([18, 47, 56])\ttarget: 57\n",
      "input: tensor([18, 47, 56, 57])\ttarget: 58\n",
      "input: tensor([18, 47, 56, 57, 58])\ttarget: 1\n",
      "input: tensor([18, 47, 56, 57, 58,  1])\ttarget: 15\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15])\ttarget: 47\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15, 47])\ttarget: 58\n"
     ]
    }
   ],
   "source": [
    "# x are the inputs to the transformer\n",
    "x = train_data[:block_size]\n",
    "# y is the next block\n",
    "y = train_data[1:block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1] # all chars of x upto t incl. t\n",
    "    target = y[t]\n",
    "    print(f'input: {context}\\ttarget: {target}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# add batching to process multiple inputs simultaneously\n",
    "batch_size = 4 # number of independent sequences to be processed parallely\n",
    "block_size = 8 # max length of the context\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # generate batch_size number of random offsets in the dataset\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # stack converts multiple rows into a list of rows\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x,y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[53, 51, 39, 52, 11,  1, 47, 44],\n",
      "        [53, 53, 51, 10,  0, 35, 46, 39],\n",
      "        [53, 49,  1, 47, 52, 42, 43, 43],\n",
      "        [43,  1, 53, 58, 46, 43, 56,  0]])\n",
      "inputs_shape: torch.Size([4, 8])\n",
      "\n",
      "inputs: tensor([[51, 39, 52, 11,  1, 47, 44,  1],\n",
      "        [53, 51, 10,  0, 35, 46, 39, 58],\n",
      "        [49,  1, 47, 52, 42, 43, 43, 42],\n",
      "        [ 1, 53, 58, 46, 43, 56,  0, 57]])\n",
      "inputs_shape: torch.Size([4, 8])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example batches\n",
    "xb, yb = get_batch('train')\n",
    "print(f'inputs: {xb}\\ninputs_shape: {xb.shape}\\n')\n",
    "print(f'inputs: {yb}\\ninputs_shape: {yb.shape}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [53]\ttarget: 51\n",
      "input: [53, 51]\ttarget: 39\n",
      "input: [53, 51, 39]\ttarget: 52\n",
      "input: [53, 51, 39, 52]\ttarget: 11\n",
      "input: [53, 51, 39, 52, 11]\ttarget: 1\n",
      "input: [53, 51, 39, 52, 11, 1]\ttarget: 47\n",
      "input: [53, 51, 39, 52, 11, 1, 47]\ttarget: 44\n",
      "input: [53, 51, 39, 52, 11, 1, 47, 44]\ttarget: 1\n",
      "input: [53]\ttarget: 53\n",
      "input: [53, 53]\ttarget: 51\n",
      "input: [53, 53, 51]\ttarget: 10\n",
      "input: [53, 53, 51, 10]\ttarget: 0\n",
      "input: [53, 53, 51, 10, 0]\ttarget: 35\n",
      "input: [53, 53, 51, 10, 0, 35]\ttarget: 46\n",
      "input: [53, 53, 51, 10, 0, 35, 46]\ttarget: 39\n",
      "input: [53, 53, 51, 10, 0, 35, 46, 39]\ttarget: 58\n",
      "input: [53]\ttarget: 49\n",
      "input: [53, 49]\ttarget: 1\n",
      "input: [53, 49, 1]\ttarget: 47\n",
      "input: [53, 49, 1, 47]\ttarget: 52\n",
      "input: [53, 49, 1, 47, 52]\ttarget: 42\n",
      "input: [53, 49, 1, 47, 52, 42]\ttarget: 43\n",
      "input: [53, 49, 1, 47, 52, 42, 43]\ttarget: 43\n",
      "input: [53, 49, 1, 47, 52, 42, 43, 43]\ttarget: 42\n",
      "input: [43]\ttarget: 1\n",
      "input: [43, 1]\ttarget: 53\n",
      "input: [43, 1, 53]\ttarget: 58\n",
      "input: [43, 1, 53, 58]\ttarget: 46\n",
      "input: [43, 1, 53, 58, 46]\ttarget: 43\n",
      "input: [43, 1, 53, 58, 46, 43]\ttarget: 56\n",
      "input: [43, 1, 53, 58, 46, 43, 56]\ttarget: 0\n",
      "input: [43, 1, 53, 58, 46, 43, 56, 0]\ttarget: 57\n"
     ]
    }
   ],
   "source": [
    "# input and target mapping for batches\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'input: {context.tolist()}\\ttarget: {target}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bigram Language Model As A Baseline Model\n",
    "\n",
    "Right now we're only predicting what comes next based on just the individual identity of a single token. This is because the tokens aren't aware of each other. They can only see themselves. So we're only making predictions based on what the actual token is.\n",
    "\n",
    "Notice that in the implementation of generate method even though we pass a sequence of characters as context, the Bigram model only looks at the last character in the sequence to make predictions for the next character. The generate method accepts a sequence as context to keep it general."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        # logits are basically the scores for the next character in a sequence\n",
    "        # channel means all the possible tokens (here chars) you can have\n",
    "        logits = self.token_embedding_table(idx) # (B, T, C) Batch, Time, Channel\n",
    "\n",
    "        # loss function\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            # logits need to be reshaped because cross_entropy expects channels as the second dimension\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            # cross_entropy calculates loss a -log likelihood: -ln(char/65)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    # idx is the current context of some characters\n",
    "    # generate function extends the input (B, T) to B by T+1, T+2 and so on...\n",
    "    # and continues to do so for max_new_tokens\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # get predictions\n",
    "            logits, _ = self(idx)\n",
    "            # focus only on the last element in the time dimension\n",
    "            logits = logits[:, -1, :]\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            # sample from the probability distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "\n",
    "        return idx"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits: tensor([[-0.9729,  0.2434, -0.1356,  ...,  0.1614, -1.3162, -0.0710],\n",
      "        [-1.3694,  0.4819, -0.6065,  ...,  1.4325,  2.7159, -0.2356],\n",
      "        [ 2.1531, -1.6002,  0.9560,  ...,  0.2818,  1.5296,  0.7737],\n",
      "        ...,\n",
      "        [ 0.5601, -2.4942, -1.4284,  ...,  0.2002, -1.6565,  0.5220],\n",
      "        [ 1.9211, -0.2959,  1.6537,  ..., -0.5056,  0.7793,  0.9916],\n",
      "        [-0.1882,  0.4575,  0.3669,  ..., -0.2465, -1.4268, -0.8499]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "loss: 4.5496134757995605\n",
      "torch.Size([32, 65])\n"
     ]
    }
   ],
   "source": [
    "# example prediction\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits, loss = m(xb, yb)\n",
    "print(f'logits: {logits}\\nloss: {loss}\\n{logits.shape}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BL&xr\n",
      "rwv!IepVIlbjFAHzCYJifXG&3&!a;pCZntuF;YjfRAuFAl;:lGJXTPYn!HM-- sWmJdL&NfcVJdF$nMvzbYjgvUpb'?vpC\n"
     ]
    }
   ],
   "source": [
    "# example generation\n",
    "# B = 1 and T = 1 to kick off the generation\n",
    "# 0 is also encoded as \\n, which is a good place to start\n",
    "idx = torch.zeros((1, 1), dtype=torch.long)\n",
    "print(decode(m.generate(idx, max_new_tokens=100)[0].tolist())) #[0] to get a single batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training The Bigram Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# creating a pytorch optimizer to get the gradients and update the parameters\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.4108874797821045\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for steps in range(10000):\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'loss: {loss.item()}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NGowerarisaxed, f I s m fouiethan ond mellchashe the THe orongendy'le, k, nk merp er q$ffffos, twidy\n",
      "A:\n",
      "Cousfress sefthe ma nd theaw'swate ghered,\n",
      "I\n",
      "Aur KETor byerin fame oGS:\n",
      "lee.\n",
      "NRFre:\n",
      "I messen:\n",
      "Cor D&\n",
      "Cl\n",
      "YWhind, her bee ted t, w trd Cotltixet ce t HENG me.\n",
      "s worede of bor t tosesthesoicassw ay ir oukipserfonove; y Gise.\n",
      "Wharar:\n",
      "Whiro th.\n",
      "W: ceandutous rtiffomy\n",
      "\n",
      "VI wemofancat r,\n",
      "Coen wher moner\n"
     ]
    }
   ],
   "source": [
    "# test generation\n",
    "print(decode(m.generate(idx, max_new_tokens=400)[0].tolist()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Implementing Self Attention\n",
    "We want the tokens to be aware of each other. Specifically we want the current token to be aware of the tokens that have appeared before (and not the tokens that come after) and couple them. To do that we calculate the average of all the previous token which then acts as the summary of all the information before the current token which it can use to predict the next token. Keep in mind this approach loses out on a lot of spacial information about the previous tokens."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 8, 2])"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B, T, C)\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# calc average of prev tokens\n",
    "# this implementation is inefficient\n",
    "xbow = torch.zeros((B, T, C)) # bow means bag of words i.e. average of the prev tokens\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev = x[b, :t+1] # everything upto the current token including the current token\n",
    "        xbow[b, t] = torch.mean(xprev, 0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[-0.0613,  1.0447],\n         [-0.9260, -0.6164],\n         [-1.5036,  0.0651],\n         [ 0.5953,  0.1343],\n         [ 1.1044, -1.5494],\n         [ 0.5825,  0.3329],\n         [ 1.2951, -0.6300],\n         [ 0.8796, -0.9741]]),\n tensor([[-0.0613,  1.0447],\n         [-0.4936,  0.2141],\n         [-0.8303,  0.1645],\n         [-0.4739,  0.1569],\n         [-0.1582, -0.1843],\n         [-0.0348, -0.0981],\n         [ 0.1552, -0.1741],\n         [ 0.2458, -0.2741]]))"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0], xbow[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using Matrix Multiplication To Make Average Calculation More Efficient"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix a:\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "matrix b:\n",
      "tensor([[5., 1.],\n",
      "        [3., 6.],\n",
      "        [4., 3.]])\n",
      "matrix c:\n",
      "tensor([[12., 10.],\n",
      "        [12., 10.],\n",
      "        [12., 10.]])\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication example\n",
    "a = torch.ones(3, 3)\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b\n",
    "print(f'matrix a:\\n{a}')\n",
    "print(f'matrix b:\\n{b}')\n",
    "print(f'matrix c:\\n{c}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 0., 0.],\n        [1., 1., 0.],\n        [1., 1., 1.]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting a lower triangular matrix\n",
    "torch.tril(torch.ones(3, 3))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matrix a:\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "matrix b:\n",
      "tensor([[3., 1.],\n",
      "        [9., 5.],\n",
      "        [1., 7.]])\n",
      "matrix c:\n",
      "tensor([[3.0000, 1.0000],\n",
      "        [6.0000, 3.0000],\n",
      "        [4.3333, 4.3333]])\n"
     ]
    }
   ],
   "source": [
    "# using a lower triangular matrix gives each element in c matrix as sum of prev elements upon matrix multiplication\n",
    "a = torch.tril(torch.ones(3, 3))\n",
    "a = a / torch.sum(a, 1, keepdim=True) # normalize each row such that sum of all elements in a row is one\n",
    "b = torch.randint(0, 10, (3, 2)).float()\n",
    "c = a @ b # in c each row will be the average of the previous rows\n",
    "print(f'matrix a:\\n{a}')\n",
    "print(f'matrix b:\\n{b}')\n",
    "print(f'matrix c:\\n{c}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 2\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim = True)\n",
    "wei"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.0613,  1.0447],\n         [-0.4936,  0.2141],\n         [-0.8303,  0.1645],\n         [-0.4739,  0.1569],\n         [-0.1582, -0.1843],\n         [-0.0348, -0.0981],\n         [ 0.1552, -0.1741],\n         [ 0.2458, -0.2741]],\n\n        [[ 1.6547,  0.5282],\n         [ 0.2378,  0.5293],\n         [ 0.3971,  0.9392],\n         [ 0.3010,  0.7072],\n         [ 0.2754,  0.6264],\n         [ 0.3268,  0.7056],\n         [ 0.1109,  0.5249],\n         [ 0.2850,  0.5235]],\n\n        [[ 1.0538,  0.1509],\n         [ 0.9856, -0.1346],\n         [ 0.4760,  0.4241],\n         [ 0.1226,  0.6300],\n         [-0.0399,  0.4964],\n         [ 0.1006,  0.6127],\n         [ 0.0724,  0.6003],\n         [-0.0534,  0.5590]],\n\n        [[ 1.1385,  0.4626],\n         [-0.0193, -0.1204],\n         [ 0.3171,  0.2542],\n         [ 0.2987,  0.1163],\n         [ 0.1737,  0.0299],\n         [ 0.3123, -0.1032],\n         [ 0.0927,  0.0549],\n         [ 0.1127,  0.2565]]])"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xbow2 = wei @ x # ((B), T, T) @ (B, T, C) -> (B, T, C) for each batch a T, T multiplies to a T, C\n",
    "xbow2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tril:\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "\n",
      "masked filled wei:\n",
      "tensor([[0., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., -inf, -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., -inf, -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., -inf, -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., -inf, -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., -inf, -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., -inf],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "\n",
      "softmaxed wei:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000],\n",
      "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250]])\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3 (using softmax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Implementing Self Attention\n",
    "\n",
    "This attention is called self attention because the keys, queries and the values, all come from the same source x.\n",
    "In encoder-decoder transformers we can have keys from x but queries and values can come from a different source. This is called cross attention where we have nodes from a separate source which we'd like to pool information from."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: tensor([[[ 0.6223,  0.6672, -0.1610, -0.5891,  0.0268, -0.4281, -0.7132,\n",
      "           0.4530,  1.0593, -0.3565, -0.0345, -0.8459,  0.8692, -0.2875,\n",
      "           0.1336,  0.4239],\n",
      "         [-0.2630,  0.2687, -0.6003, -0.8501, -0.0380, -0.6245, -0.0931,\n",
      "          -0.4417,  1.2339, -0.4511,  0.8644,  0.3217, -0.0086, -0.2291,\n",
      "           0.2228,  1.0264],\n",
      "         [ 0.9350,  0.8069, -0.5908,  0.5710,  0.4617, -0.2731,  0.0925,\n",
      "           0.3897,  0.2646,  1.0613, -1.3004,  0.1308, -0.4151,  0.0740,\n",
      "          -0.5951, -0.7345],\n",
      "         [ 0.8388, -0.2040, -0.7414,  0.2889,  0.0683,  0.0270,  0.6034,\n",
      "           0.7024, -0.2394, -0.2562,  0.2582,  0.2980, -0.1518,  0.4322,\n",
      "           0.3429, -0.7432],\n",
      "         [-0.2021, -0.9490, -0.0956,  0.5241,  1.0297, -0.0988, -0.3211,\n",
      "           0.4393, -1.2442, -0.0778, -0.2027,  0.0133,  0.1113,  0.3739,\n",
      "           0.6861, -1.0965],\n",
      "         [-0.2959, -0.1842,  0.1077, -0.4384,  0.1618,  0.4899, -0.5088,\n",
      "          -0.4491, -0.3239, -0.3367, -0.0535, -0.0492,  0.9277,  0.1868,\n",
      "          -0.3974,  1.0982],\n",
      "         [ 0.2182,  0.4004, -0.6232,  0.2490,  0.0895,  0.7762, -0.0967,\n",
      "          -0.6267, -0.3467, -0.0027,  0.1118, -0.4921, -0.5357,  0.0928,\n",
      "           0.0169,  0.3214],\n",
      "         [ 0.2367,  0.9657, -0.8756, -0.3481,  0.5732, -0.2483, -0.1990,\n",
      "          -0.1202,  0.3976,  0.8443, -0.5369, -0.1362,  0.0950,  0.0577,\n",
      "          -0.0431, -0.6380]],\n",
      "\n",
      "        [[-0.5323, -0.1887, -0.6836,  0.5997,  0.7415, -0.5671,  0.2673,\n",
      "          -1.0200, -0.2872,  0.1169,  0.0549,  0.7350, -0.1880, -0.2433,\n",
      "           1.2354,  0.0026],\n",
      "         [ 1.0272,  0.2662,  0.2802,  0.1463,  0.2882, -1.1786,  0.3408,\n",
      "          -0.3795, -0.2984,  0.8183, -0.0990,  1.0057, -0.8059,  0.5170,\n",
      "           0.1915,  0.5109],\n",
      "         [-0.0117, -0.9761, -0.4078,  0.0935,  0.1337, -0.3513, -0.3746,\n",
      "          -0.2688,  0.0316, -0.4713,  0.1895, -0.3706,  0.7491,  0.3256,\n",
      "          -0.0959,  0.7092],\n",
      "         [ 0.2331,  0.2159,  0.7655,  0.3818,  1.0528, -0.9344,  0.2678,\n",
      "          -0.5520,  0.2358,  0.1594, -0.4311,  0.1406, -0.3737, -0.7005,\n",
      "          -0.6921, -0.7682],\n",
      "         [ 0.0813,  0.5638, -0.6574, -0.4332, -0.5131,  1.1896, -0.0890,\n",
      "           0.1542, -0.2008,  0.5830, -0.2986, -0.5671, -0.1119,  0.7863,\n",
      "          -0.3359,  1.2693],\n",
      "         [-0.3069, -1.0539, -0.1781, -0.3945, -0.5658,  0.3097,  0.0396,\n",
      "           0.5530, -0.7393, -0.6486,  0.4567,  0.7558, -0.2126,  1.2537,\n",
      "           0.7701,  0.1539],\n",
      "         [-0.5427, -0.0297,  0.1610, -0.0655,  0.3536,  0.1053,  0.0996,\n",
      "           0.4813,  1.4353, -0.3199,  0.5228,  0.6202, -0.1419, -1.4946,\n",
      "          -0.5519,  0.1411],\n",
      "         [ 0.0977,  0.7345,  0.1551,  0.8890, -0.2604,  1.3399,  0.8582,\n",
      "           1.3134, -0.4488,  0.5301, -0.6935,  0.3746, -0.2050,  0.2301,\n",
      "          -0.6300, -0.6449]],\n",
      "\n",
      "        [[ 0.2506,  0.6423,  0.3510,  0.2049, -0.4493, -0.0898, -0.3400,\n",
      "           0.1133,  0.3372,  0.3123, -0.3513, -0.6642, -0.1177, -0.1233,\n",
      "          -0.5064, -0.1096],\n",
      "         [ 0.0822, -1.0608,  0.3731, -0.3331,  0.1804, -0.2861, -0.4047,\n",
      "          -0.5536, -1.1132, -0.7350, -0.4893, -0.4723,  0.4331,  1.3324,\n",
      "          -0.5252,  0.5443],\n",
      "         [-1.0552, -0.4060,  0.2530,  0.0934, -0.3879,  0.5011,  0.7019,\n",
      "           0.5325, -0.4586, -0.8481,  0.5927, -0.5736,  0.3865,  0.9807,\n",
      "          -0.7962, -0.1366],\n",
      "         [-0.1895,  1.4664,  0.1054, -0.8558,  0.1749, -0.5958, -0.5572,\n",
      "           0.1372,  0.7107,  0.4385, -0.0099, -0.4802,  0.1774, -0.4567,\n",
      "          -0.7077,  1.1251],\n",
      "         [-0.5595, -0.3721, -0.2618,  0.0700, -0.0533,  0.1532,  0.0487,\n",
      "          -0.3038, -0.0738, -0.5750,  0.2191,  0.8643, -0.0466, -0.4839,\n",
      "          -0.0344,  1.5808],\n",
      "         [-0.4524, -0.7413, -0.3223,  0.0650,  0.7557, -0.0752, -0.9917,\n",
      "           0.2645, -0.8369,  0.6039, -1.0438,  1.0820,  0.7878,  1.0225,\n",
      "           0.0659, -0.6183],\n",
      "         [-0.5543, -0.0668,  0.1440,  0.0249, -0.3958, -0.5676, -0.5284,\n",
      "          -1.1394,  0.1246,  0.5271, -0.7110, -0.2330,  0.1440, -0.7229,\n",
      "          -0.0076,  0.1806],\n",
      "         [-0.6121, -0.0886, -0.4111, -1.0969,  0.2585, -0.4550, -0.5612,\n",
      "           0.4098,  0.7295, -0.0434, -0.0478,  0.1273, -0.3956,  0.1807,\n",
      "           0.9617, -0.3680]],\n",
      "\n",
      "        [[-0.2242,  0.2221,  0.1626, -0.3116,  0.4868, -0.6929,  0.4611,\n",
      "           0.3794, -0.4005, -0.0180, -0.6055,  1.2752,  0.1908, -0.1207,\n",
      "           0.3104,  0.7557],\n",
      "         [ 0.7551,  0.4841,  0.1246,  0.4120,  0.2496, -0.5868,  0.2656,\n",
      "           0.4217,  0.0444,  0.7349, -0.1858, -0.7343, -0.5620, -0.2423,\n",
      "          -0.0585, -0.3261],\n",
      "         [ 0.0319,  0.4142, -0.2963,  0.6115,  0.2156,  0.6073,  0.3905,\n",
      "           0.0594, -0.9105,  0.4017, -0.2701,  0.1565, -0.9541, -0.0234,\n",
      "           0.0682, -0.9213],\n",
      "         [-0.1210, -0.0383,  0.1373,  0.4823,  0.2348,  0.2634,  0.2788,\n",
      "          -0.3378, -0.8665, -0.2196,  0.0198,  1.2131,  0.3261, -0.4036,\n",
      "          -0.1634, -0.2460],\n",
      "         [ 0.0964, -1.0106,  0.1741, -0.0174, -0.3332, -0.3716, -0.9056,\n",
      "           0.2162,  0.0695, -0.6397, -0.0721, -0.5425,  0.3932,  0.8054,\n",
      "          -0.2711,  0.3602],\n",
      "         [ 0.7671,  1.1712, -0.3221, -1.1926,  0.2724,  1.0124,  0.2438,\n",
      "           0.9416,  0.8021, -0.1098,  1.1182, -0.5094, -0.1200, -0.0333,\n",
      "          -0.4648, -0.1161],\n",
      "         [ 0.4945,  0.0241,  0.3711, -0.4519,  0.4445, -0.6400, -0.3838,\n",
      "          -0.2381, -0.4319, -0.2288, -0.7947, -0.2658,  0.4568,  0.5667,\n",
      "           0.2132, -1.2468],\n",
      "         [ 1.7134,  0.0371,  0.7897,  0.9444,  0.0936, -0.1976,  0.8966,\n",
      "          -0.3244, -1.8600, -0.9852,  0.9694, -0.1545, -0.2928,  0.2937,\n",
      "           0.2859, -0.6450]]], grad_fn=<UnsafeViewBackward0>)\n",
      "query: tensor([[[ 0.3385, -0.9256, -0.6292,  0.0813,  0.5488,  0.3908, -0.7746,\n",
      "          -0.0792,  0.3756,  0.7180,  0.2054, -0.5607, -0.6865, -0.0052,\n",
      "           0.4125,  0.4960],\n",
      "         [-0.1529, -0.4890, -0.0399,  0.3665, -0.2148,  0.4822, -0.1361,\n",
      "          -0.1522, -0.4357,  0.1187,  0.0867, -0.7679,  0.0567,  0.4075,\n",
      "           0.1089, -0.5429],\n",
      "         [ 0.0836, -0.1931, -0.4603,  0.3932, -0.2469,  0.4955, -0.6831,\n",
      "          -0.0169, -0.1675, -0.4765, -0.3988,  0.0932,  1.0599, -0.1297,\n",
      "           0.1918, -0.5953],\n",
      "         [ 0.3741, -0.9007, -0.1507, -0.1376,  0.8547, -0.4359,  0.7834,\n",
      "          -0.3910, -0.1894,  0.4699, -0.2897,  0.4941,  0.0340, -0.3965,\n",
      "           0.1685, -0.6103],\n",
      "         [ 0.3709, -0.3847,  0.3804,  1.5088,  0.8500,  0.6650,  0.0024,\n",
      "           0.4693,  0.0174,  0.5509,  0.2988,  1.3830,  0.3059, -0.8360,\n",
      "          -0.6902,  0.2303],\n",
      "         [ 0.6623, -0.4452,  0.0958,  0.3608,  0.1251,  0.0654,  0.3465,\n",
      "          -0.5880, -0.1071,  0.7452, -0.2351,  0.3115,  0.2047, -0.4207,\n",
      "           0.5380,  0.6502],\n",
      "         [-0.1569,  0.5419,  0.0860, -0.3839,  0.5000, -0.6807,  0.6049,\n",
      "          -0.2769, -0.0417,  0.0920,  0.1200, -0.1779, -0.4928, -0.1597,\n",
      "          -0.0342,  0.6017],\n",
      "         [-0.0623, -0.4361, -0.4545,  0.0496, -0.0955,  0.1615, -0.5852,\n",
      "          -0.4356, -0.7501,  0.1154, -0.7435,  0.5060,  0.9491, -0.3070,\n",
      "          -0.0948,  0.3729]],\n",
      "\n",
      "        [[ 0.0919, -1.2140,  0.8572,  0.6447,  0.5133, -0.4999,  0.3197,\n",
      "          -0.6073, -0.9528, -0.0602, -0.5259,  1.1121,  0.3309, -0.9945,\n",
      "          -0.4174,  0.1526],\n",
      "         [ 0.5044, -0.1702,  0.5677,  0.5608,  0.4223, -0.3002, -0.6174,\n",
      "          -0.3420, -0.2467,  0.2106, -0.0774,  0.1886,  0.0966, -0.4799,\n",
      "           0.3868, -0.6089],\n",
      "         [-0.2726, -0.0832,  0.2574,  0.1760,  0.0577, -0.6016, -0.0203,\n",
      "           0.2454,  0.3934,  1.0014, -0.2142,  0.2654, -0.3403, -0.1363,\n",
      "           0.0634,  0.5334],\n",
      "         [ 0.2966, -0.2164,  0.2735,  1.2783, -1.0019,  1.2166, -1.0163,\n",
      "          -0.0978,  0.5169,  0.0602,  0.4830, -0.1834,  0.9608, -0.4120,\n",
      "           0.3348, -0.5651],\n",
      "         [-0.1558, -0.4359, -0.0525, -0.3059,  0.3402,  0.0650,  0.1697,\n",
      "           0.0578, -0.9534, -0.4926,  0.3506, -0.4671, -0.0890,  0.5703,\n",
      "           0.8146, -0.0789],\n",
      "         [ 0.2407,  0.6157,  0.1566, -1.1129, -0.2970, -0.2580,  0.4596,\n",
      "          -0.2783,  0.9313,  0.5515, -0.3732, -0.0234, -0.7327,  0.3298,\n",
      "          -0.4319, -0.2233],\n",
      "         [-0.1658,  0.5470,  0.0161, -0.0830, -0.7920,  0.6298,  0.2646,\n",
      "          -0.7825,  1.0599, -0.2280,  0.5209, -0.6517,  0.1817,  0.3162,\n",
      "          -0.1312,  0.2898],\n",
      "         [-0.1074,  0.6392,  0.1573, -0.1264,  0.5724,  0.3338,  0.6950,\n",
      "          -0.4385, -0.3623,  0.2334,  0.0336,  0.7011, -0.0702, -0.9176,\n",
      "           0.1959,  0.1278]],\n",
      "\n",
      "        [[-0.1077,  0.1083,  0.1227,  0.0990, -0.3999, -0.2468, -0.6591,\n",
      "           0.1635, -0.0091, -0.5903, -0.0953, -0.6510,  0.1780,  0.2498,\n",
      "          -0.2770, -0.0768],\n",
      "         [ 0.4127,  0.0448,  0.5224, -0.0184, -0.6527, -0.2352, -0.0446,\n",
      "          -0.2998,  0.2122,  0.3183,  0.0991,  0.1508, -0.3004,  0.3485,\n",
      "           0.5454,  0.0950],\n",
      "         [-0.2477, -0.7369,  1.3574, -0.3673, -0.0143, -0.5707,  1.1233,\n",
      "          -0.3710, -0.7771, -0.1248,  0.0143, -1.0484, -0.2270, -0.3157,\n",
      "           0.0088, -0.4438],\n",
      "         [ 0.6207, -0.9643,  0.0543,  0.0302,  0.0665,  0.8485, -0.2185,\n",
      "          -0.6821, -0.3732, -0.2188,  0.9066, -0.2917,  0.5431,  0.1098,\n",
      "           0.9424,  0.5035],\n",
      "         [ 0.2765,  0.0360,  0.2694, -0.5237,  1.2986, -1.1194,  1.5176,\n",
      "          -0.7828, -0.3624,  0.1689, -0.2826, -0.0117, -0.0850, -0.1775,\n",
      "           0.6946,  0.5195],\n",
      "         [ 0.6145, -0.3594,  0.1607,  1.2490,  0.5541,  0.5940, -0.3978,\n",
      "           1.2780,  0.4847,  0.5520, -0.1091,  0.7587, -0.2573, -0.1850,\n",
      "          -0.9092, -0.0781],\n",
      "         [-0.7573, -0.6411, -0.3573, -0.0167,  0.7942,  0.1203,  0.0469,\n",
      "           0.8074, -0.8687,  0.5429,  0.5001, -0.2929,  0.0174, -0.0266,\n",
      "           0.6489,  0.0420],\n",
      "         [-0.0518, -0.2612, -0.8444,  0.0929, -0.0168,  0.4344, -0.1080,\n",
      "           0.3519,  0.1214,  0.5475,  0.0456, -0.2302, -0.4054,  0.1562,\n",
      "           0.1613,  0.0996]],\n",
      "\n",
      "        [[ 0.9678, -0.8292,  0.2988, -0.6094,  0.3571,  0.3243, -0.1265,\n",
      "          -1.2152,  0.0061,  1.1862, -0.4282,  0.5336, -0.3554, -0.5387,\n",
      "           0.5026,  0.7226],\n",
      "         [-0.1556,  0.2756,  0.3124,  0.5419,  0.3316, -0.5044, -0.0604,\n",
      "          -0.2047,  0.1627, -0.8254,  0.6026,  0.2483,  0.4243,  0.1638,\n",
      "           0.2162,  0.2510],\n",
      "         [ 0.0663,  0.8552, -0.3516, -0.6922, -0.4966,  0.2179,  0.6633,\n",
      "           0.2029, -0.3126, -0.5359,  0.3585, -0.3556, -0.3775, -0.3400,\n",
      "          -0.4870, -0.1542],\n",
      "         [ 0.5264,  0.6246, -0.0751, -0.6298,  0.6870, -0.1633,  1.0000,\n",
      "          -0.3325,  0.0954,  0.2277, -0.4055,  0.8059,  0.0700, -0.3944,\n",
      "          -0.3957,  0.2348],\n",
      "         [ 0.4125,  0.3378,  0.9692, -0.1915, -0.3801, -0.5137,  0.1015,\n",
      "          -0.3726,  0.9622, -0.2976, -0.0369, -0.6185, -0.6327,  1.0107,\n",
      "          -0.6317, -0.1159],\n",
      "         [ 1.0882, -1.0875, -0.6726, -1.8377, -0.5892, -0.1581,  0.2268,\n",
      "          -1.3151,  0.2984,  0.1726, -0.2469, -0.0200, -0.0628,  0.4000,\n",
      "           0.5323,  0.5451],\n",
      "         [ 0.4584,  0.0713, -0.6516,  0.6723, -0.6337,  0.6374, -1.3228,\n",
      "           0.7293,  1.0494, -0.3989, -0.0417, -0.5816, -0.4678,  1.2511,\n",
      "          -0.5160, -0.4341],\n",
      "         [ 1.9606, -0.5669,  0.2318,  0.0809, -0.1812,  0.1931, -0.2081,\n",
      "          -1.3315, -0.6972,  0.1293,  0.0600, -0.5895, -0.2864, -0.6851,\n",
      "           1.5092, -0.5208]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "key_shape: torch.Size([4, 8, 16])\n",
      "query_shape: torch.Size([4, 8, 16])\n",
      "\n",
      "out: tensor([[[ 1.3446e-01,  3.1918e-02,  6.5406e-02, -1.2806e-01,  3.1501e-02,\n",
      "          -3.3799e-02, -1.6766e-01, -1.3453e-02,  5.0150e-02, -6.2028e-02,\n",
      "          -1.4007e-01, -4.0281e-03,  3.9171e-02,  9.0560e-02,  4.4610e-02,\n",
      "          -3.6906e-02],\n",
      "         [ 2.1170e-01, -3.5861e-02,  5.5925e-04, -1.5527e-01,  9.2484e-02,\n",
      "           7.5695e-04, -2.0913e-01,  2.0636e-02,  1.0148e-02, -9.4961e-03,\n",
      "          -1.1002e-01,  5.3713e-02,  1.1702e-01,  4.9555e-02, -1.4677e-02,\n",
      "          -2.2491e-02],\n",
      "         [ 1.6702e-01,  4.0713e-02, -1.1756e-01, -1.9296e-01, -4.6443e-02,\n",
      "          -7.9458e-02, -2.6145e-01,  2.5572e-02,  2.6331e-02,  5.7074e-02,\n",
      "          -1.1368e-01,  4.7867e-02,  6.6108e-02,  1.5036e-01,  8.5252e-02,\n",
      "          -1.2188e-01],\n",
      "         [-4.2224e-02,  2.1563e-02, -3.0658e-01, -3.4389e-01, -5.4338e-01,\n",
      "           2.2841e-04, -4.2365e-02,  2.4254e-01,  1.3548e-01,  1.4371e-01,\n",
      "           8.4808e-02,  5.8621e-02, -4.1898e-02,  5.1196e-02,  2.5098e-01,\n",
      "          -9.7707e-02],\n",
      "         [-1.1545e-01,  1.6791e-01, -1.7271e-01,  2.5069e-02, -6.1815e-01,\n",
      "           2.5329e-01, -1.9506e-01, -1.0726e-01,  2.1088e-01,  3.3925e-01,\n",
      "           2.8218e-01,  2.1790e-01,  8.5678e-02, -9.8601e-02,  2.6784e-01,\n",
      "           1.3297e-01],\n",
      "         [ 2.9571e-02,  1.6105e-01, -2.0171e-01, -1.0997e-01, -3.6535e-01,\n",
      "           2.1918e-01, -3.3813e-01, -3.5257e-01,  9.9026e-03,  3.6065e-01,\n",
      "           1.9120e-01,  2.1480e-01,  2.4409e-02,  1.2742e-03, -2.9403e-02,\n",
      "           3.5615e-02],\n",
      "         [ 9.4555e-02, -6.5899e-02, -1.7013e-01, -1.8496e-01, -4.1616e-01,\n",
      "           1.2406e-01, -4.1894e-01, -7.3401e-02,  8.4625e-02, -1.2594e-01,\n",
      "           1.4678e-01,  3.7653e-02,  2.8348e-01, -1.4897e-01,  1.2377e-01,\n",
      "           5.2220e-02],\n",
      "         [ 6.0304e-02,  4.1427e-01, -2.1723e-02,  3.1531e-01, -6.3901e-01,\n",
      "           2.3047e-01, -9.2912e-01, -1.1575e+00, -4.9189e-01,  3.9877e-01,\n",
      "           4.0782e-01, -7.8667e-01, -8.7276e-02,  2.2429e-01, -1.3967e-01,\n",
      "           2.5660e-01]],\n",
      "\n",
      "        [[ 4.2359e-02, -2.2676e-01, -3.5866e-02, -4.7522e-02,  5.2765e-02,\n",
      "          -1.2989e-01, -7.3782e-02, -5.8487e-02, -3.9227e-02,  4.5654e-02,\n",
      "           1.0174e-01,  1.8345e-01, -3.0003e-02,  3.5535e-02, -1.8882e-01,\n",
      "           7.3549e-02],\n",
      "         [-2.6638e-02, -2.0904e-01, -1.3594e-01,  3.9609e-02,  1.5869e-01,\n",
      "          -1.3016e-01, -1.6238e-01,  3.2431e-03, -1.0390e-01,  1.4623e-01,\n",
      "           2.1458e-01,  2.4906e-01,  1.1318e-01,  5.8778e-02, -1.1497e-01,\n",
      "          -8.6552e-02],\n",
      "         [-1.1337e-01, -3.9708e-02, -8.7821e-02, -6.5785e-02,  1.6467e-01,\n",
      "          -5.7553e-02, -1.7650e-01, -2.5362e-02, -6.5070e-02,  1.6184e-01,\n",
      "           1.9164e-01,  1.7374e-01,  6.5784e-02,  1.0009e-01,  2.4059e-02,\n",
      "          -5.3551e-02],\n",
      "         [-1.8229e-01,  1.3012e-01, -1.1580e-01, -1.2020e-01,  1.2054e-01,\n",
      "          -5.4796e-02, -2.8539e-02, -1.3655e-01,  3.3998e-02,  2.0978e-01,\n",
      "           1.1891e-01,  4.1310e-02, -7.0613e-02,  1.0578e-01,  1.4884e-02,\n",
      "           8.6313e-02],\n",
      "         [-8.6360e-02, -4.3442e-02, -3.1859e-01, -1.1894e-01,  1.8882e-01,\n",
      "          -9.2357e-02, -3.0689e-01, -1.6899e-01,  8.0357e-02,  4.2510e-01,\n",
      "           2.5314e-01,  2.5634e-01,  2.1086e-01, -9.4607e-03, -5.0909e-02,\n",
      "           4.0951e-02],\n",
      "         [-3.0764e-01,  1.3188e-01, -4.8414e-01,  1.5858e-01,  3.3325e-01,\n",
      "           5.6559e-02, -3.8009e-01, -5.5008e-01,  4.3111e-02,  7.3883e-01,\n",
      "           5.4220e-01,  1.5407e-01,  2.4094e-01, -2.1837e-01,  3.6468e-01,\n",
      "          -2.2269e-01],\n",
      "         [-2.2584e-01,  5.2389e-02, -2.1547e-01, -1.5374e-02,  4.7117e-01,\n",
      "          -2.9148e-01, -1.8408e-02, -7.4371e-01,  1.2910e-03,  7.6637e-01,\n",
      "           6.7667e-01,  3.3076e-01, -9.1673e-02, -1.5705e-01,  3.6138e-01,\n",
      "          -1.6678e-01],\n",
      "         [-1.0891e+00, -5.7018e-01, -8.9591e-01,  1.1227e+00, -3.8160e-02,\n",
      "          -1.1101e+00,  1.9768e-01, -8.5102e-01, -1.2898e-01,  1.5277e+00,\n",
      "           1.5274e+00,  4.3428e-01, -4.1690e-01,  4.2092e-01, -4.0692e-01,\n",
      "          -2.2415e-01]],\n",
      "\n",
      "        [[ 1.7500e-02, -6.7460e-02, -1.2826e-01,  7.3773e-02,  2.0699e-02,\n",
      "          -3.3870e-02,  8.5165e-02, -5.2955e-02, -3.1884e-02, -6.2489e-02,\n",
      "          -2.3229e-02, -6.9481e-02, -5.1801e-02,  1.2422e-02,  1.4695e-02,\n",
      "          -4.2395e-02],\n",
      "         [-8.4766e-02,  9.6852e-02, -7.7253e-02, -3.1511e-02,  4.6437e-02,\n",
      "           2.1484e-02,  9.1890e-02, -3.4933e-02, -9.0857e-02, -1.7201e-02,\n",
      "          -5.0348e-02, -1.7653e-02, -7.3215e-03,  5.5511e-02,  4.5699e-02,\n",
      "          -3.1025e-03],\n",
      "         [-1.8225e-01,  1.9975e-01, -3.1711e-01, -1.7840e-01,  1.5105e-01,\n",
      "           8.9495e-02,  1.7382e-01,  1.9774e-02, -2.5543e-01,  1.5213e-01,\n",
      "          -1.1406e-01, -3.5329e-02,  4.7916e-01, -1.1247e-01, -1.0707e-01,\n",
      "           2.1581e-01],\n",
      "         [-9.5215e-02,  5.3568e-02, -2.4004e-01, -8.6514e-02,  2.9772e-01,\n",
      "           1.6475e-01,  1.3500e-01,  2.3499e-02, -3.6998e-01,  1.7556e-01,\n",
      "          -1.0790e-01, -8.3496e-03,  5.3199e-01, -4.6123e-02, -2.1594e-01,\n",
      "           1.2152e-01],\n",
      "         [-1.1219e-01, -1.9254e-01, -5.1565e-02, -7.0460e-02,  2.8828e-01,\n",
      "           3.9328e-02,  3.2933e-01,  1.6101e-01, -5.5813e-01, -1.8513e-01,\n",
      "          -8.0495e-03,  1.5749e-01,  3.8256e-01,  1.2504e-01, -3.3282e-01,\n",
      "           3.6277e-02],\n",
      "         [-2.6997e-01,  1.2831e-01, -4.4007e-01,  2.4440e-01,  3.9223e-01,\n",
      "          -5.8438e-02,  2.4792e-02, -1.4476e-01, -4.7469e-01,  4.4412e-01,\n",
      "           1.9374e-01,  4.0663e-01,  5.1564e-01, -1.4824e-02, -3.3983e-01,\n",
      "          -3.1225e-01],\n",
      "         [-4.0437e-01,  4.3856e-01, -7.5874e-02, -4.1153e-03,  4.8994e-01,\n",
      "          -3.8433e-01, -1.6484e-01, -1.7376e-01,  1.2084e-01,  7.2949e-01,\n",
      "           2.9755e-01,  3.5734e-01,  3.9077e-01,  3.0715e-01, -6.8138e-01,\n",
      "          -2.3217e-01],\n",
      "         [-6.5580e-01,  7.9487e-01,  2.3027e-01, -3.9352e-01,  7.7091e-01,\n",
      "          -1.2029e+00, -1.3738e+00,  4.2727e-01,  4.4964e-01, -5.6548e-03,\n",
      "          -5.3668e-01,  2.8405e-01, -3.7026e-02,  7.5642e-01, -7.0588e-01,\n",
      "          -6.4532e-01]],\n",
      "\n",
      "        [[-6.2596e-02, -1.1962e-02,  8.9724e-02,  1.2136e-01,  6.7874e-02,\n",
      "          -1.1925e-01, -8.7555e-02, -1.2646e-01, -1.7335e-01,  1.1877e-01,\n",
      "           9.0753e-02,  3.0649e-02, -5.1448e-02,  1.5837e-01, -1.8413e-02,\n",
      "          -6.4192e-02],\n",
      "         [-1.0429e-01, -5.5284e-03, -1.1783e-02,  1.5452e-01,  3.6821e-02,\n",
      "          -4.9483e-02, -2.8867e-02, -1.4008e-01, -1.7527e-01,  1.5104e-01,\n",
      "           1.1282e-01,  7.1307e-02, -1.9901e-02,  1.5233e-01,  5.5726e-02,\n",
      "          -1.9284e-02],\n",
      "         [-2.1092e-01, -7.0007e-02, -5.0851e-02,  4.1573e-01, -1.6274e-01,\n",
      "           2.4331e-02, -6.2841e-03, -1.0018e-01, -1.4680e-01,  1.0739e-01,\n",
      "           2.2973e-01, -1.5114e-02, -1.1742e-01,  7.6744e-02,  8.9193e-02,\n",
      "          -2.7666e-02],\n",
      "         [-3.5227e-01, -9.7623e-02,  3.4848e-01,  6.1567e-01, -3.3612e-01,\n",
      "           2.0043e-02,  2.9622e-01, -8.1254e-02, -4.3004e-01,  9.0801e-04,\n",
      "           4.3142e-01, -6.1737e-02, -2.9587e-01,  2.2789e-01, -1.7973e-02,\n",
      "          -1.1176e-01],\n",
      "         [-2.5678e-01,  9.5928e-02,  7.7412e-02,  9.1005e-02, -1.9015e-01,\n",
      "           3.3563e-02,  3.7060e-01, -9.5892e-02, -2.9150e-01,  2.3173e-02,\n",
      "           2.3130e-01,  2.1341e-01, -7.4305e-02,  1.6861e-01,  3.1137e-01,\n",
      "          -1.1623e-01],\n",
      "         [-6.5095e-02, -2.6327e-01,  9.5740e-02, -3.0282e-01, -2.7412e-01,\n",
      "           7.0109e-02,  4.6747e-01,  1.7723e-01, -4.4812e-01, -1.7783e-01,\n",
      "           9.8782e-02, -1.4393e-01, -3.6277e-02,  5.0175e-03,  2.3314e-01,\n",
      "          -8.0489e-02],\n",
      "         [-1.9622e-02,  1.1641e-01, -5.1939e-01, -7.3737e-01, -3.2728e-01,\n",
      "           2.6539e-01,  4.3271e-01,  1.7710e-01, -4.2899e-01,  1.4695e-01,\n",
      "          -1.4363e-01, -5.7139e-02,  2.2793e-01, -2.8475e-01,  7.3842e-01,\n",
      "          -1.3216e-01],\n",
      "         [ 1.2906e-01,  9.4660e-01, -9.3811e-01, -3.3010e-01, -9.9476e-01,\n",
      "           1.0575e+00, -5.6223e-01, -4.2081e-01, -9.7193e-01,  6.8287e-01,\n",
      "           1.6084e-01,  3.4746e-01,  7.2639e-01, -7.9502e-01,  1.3462e+00,\n",
      "           9.4740e-01]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "out_shape: torch.Size([4, 8, 16])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# create a single head of self attention\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x) # (B, T, 16)\n",
    "q = query(x) # (B, T, 16)\n",
    "v = value(x)\n",
    "# transpose last two dimensions to multiply\n",
    "# (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5 # multiply with sqrt of head_size to bring down variance to order of 1\n",
    "\n",
    "print(f'key: {k}\\nquery: {q}\\n')\n",
    "print(f'key_shape: {k.shape}\\nquery_shape: {q.shape}\\n')\n",
    "\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "# we have implemented a decoder block\n",
    "# to make it an encoder block we simply remove this line\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim=1)\n",
    "out = wei @ v\n",
    "\n",
    "print(f'out: {out}\\n')\n",
    "print(f'out_shape: {out.shape}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.1503, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1101, 0.1001, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.1659, 0.1213, 0.1428, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0924, 0.1336, 0.1980, 0.2620, 0.0000, 0.0000, 0.0000, 0.0000],\n        [0.0875, 0.1096, 0.2102, 0.2217, 0.2981, 0.0000, 0.0000, 0.0000],\n        [0.1191, 0.1577, 0.1615, 0.1890, 0.2277, 0.2880, 0.0000, 0.0000],\n        [0.1456, 0.2414, 0.1467, 0.1643, 0.1740, 0.2599, 0.5100, 0.0000],\n        [0.1291, 0.1361, 0.1408, 0.1630, 0.3002, 0.4521, 0.4900, 1.0000]],\n       grad_fn=<SelectBackward0>)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
