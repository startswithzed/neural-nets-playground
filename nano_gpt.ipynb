{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "!pip install -Uqq torch\n",
    "!pip install -Uqq numpy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Raw Implementation Of GPT Like Model\n",
    "### Download The Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-07 12:13:14--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1115394 (1.1M) [text/plain]\r\n",
      "Saving to: ‘input.txt.1’\r\n",
      "\r\n",
      "input.txt.1         100%[===================>]   1.06M   914KB/s    in 1.2s    \r\n",
      "\r\n",
      "2023-03-07 12:13:17 (914 KB/s) - ‘input.txt.1’ saved [1115394/1115394]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "with open('data/tinyshakespeare.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect The Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "1115394"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# first 1000 characters\n",
    "print(text[:1000])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get The Vocabulary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n"
     ]
    },
    {
     "data": {
      "text/plain": "65"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get set of all chars in the text and then get that as a sorted list\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "vocab_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenize The Input\n",
    "Since this is a character level language model, we'll just translate individual characters to integers.\n",
    "\n",
    "Other tokenizers to look into:\n",
    "1. SentencePiece (Google)\n",
    "2. Tiktoken (OpenAI)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42, 2]\n",
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i, ch in enumerate(chars) }\n",
    "itos = { i:ch for i, ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # take a string and output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # take a list of integers and output a string\n",
    "\n",
    "print(encode(\"Hello World!\"))\n",
    "print(decode(encode(\"Hello World!\")))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "dict"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stoi is a lookup table where key is the index and value is the character\n",
    "type(stoi)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115394]) torch.int16\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0], dtype=torch.int16)\n"
     ]
    }
   ],
   "source": [
    "# encode the dataset and get a tensor\n",
    "# data type is int16 because our vocab size is only 65\n",
    "data = torch.tensor(encode(text), dtype=torch.int16)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Training and Validation Splits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(1003854, 111540)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = int(0.9*len(data)) # split 90% of data\n",
    "train_data = data[:n] # first 90% is training data\n",
    "val_data = data[n:] # rest is validation data\n",
    "\n",
    "len(train_data), len(val_data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Batches Of Data To Train The Model\n",
    "\n",
    "Sample random chunks of data from the training set. These chunks are of fixed max length.\n",
    "In a chunk of 9 characters like `[18, 47, 56, 57, 58,  1, 15, 47, 58]` there are 8 examples for the model to train itself on like:\n",
    "1. In the context of 18, 47 likely comes next.\n",
    "2. In the context of 18 and 47, 56 likely comes next and so on.\n",
    "\n",
    "This also helps the transformer network get used to seeing context length of 1 character upto the max context length."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58], dtype=torch.int16)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8 # max length of chunks\n",
    "train_data[:block_size + 1] # first 9 chars in the training set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([18], dtype=torch.int16)\ttarget: 47\n",
      "input: tensor([18, 47], dtype=torch.int16)\ttarget: 56\n",
      "input: tensor([18, 47, 56], dtype=torch.int16)\ttarget: 57\n",
      "input: tensor([18, 47, 56, 57], dtype=torch.int16)\ttarget: 58\n",
      "input: tensor([18, 47, 56, 57, 58], dtype=torch.int16)\ttarget: 1\n",
      "input: tensor([18, 47, 56, 57, 58,  1], dtype=torch.int16)\ttarget: 15\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15], dtype=torch.int16)\ttarget: 47\n",
      "input: tensor([18, 47, 56, 57, 58,  1, 15, 47], dtype=torch.int16)\ttarget: 58\n"
     ]
    }
   ],
   "source": [
    "# x are the inputs to the transformer\n",
    "x = train_data[:block_size]\n",
    "# y is the next block\n",
    "y = train_data[1:block_size + 1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1] # all chars of x upto t incl. t\n",
    "    target = y[t]\n",
    "    print(f'input: {context}\\ttarget: {target}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# add batching to process multiple inputs simultaneously\n",
    "batch_size = 4 # number of independent sequences to be processed parallely\n",
    "block_size = 8 # max length of the context\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate a small batch of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    # generate batch_size number of random offsets in the dataset\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix]) # stack converts multiple rows into a list of rows\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "\n",
    "    return x,y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs: tensor([[11,  0, 32, 46, 39, 58,  1, 61],\n",
      "        [43, 50, 53, 11,  0, 21, 52,  1],\n",
      "        [53, 53,  1, 50, 47, 58, 58, 50],\n",
      "        [32, 47, 57,  1, 53, 52, 43,  1]], dtype=torch.int16)\n",
      "inputs_shape: torch.Size([4, 8])\n",
      "\n",
      "inputs: tensor([[ 0, 32, 46, 39, 58,  1, 61, 47],\n",
      "        [50, 53, 11,  0, 21, 52,  1, 58],\n",
      "        [53,  1, 50, 47, 58, 58, 50, 43],\n",
      "        [47, 57,  1, 53, 52, 43,  1, 58]], dtype=torch.int16)\n",
      "inputs_shape: torch.Size([4, 8])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# example batches\n",
    "xb, yb = get_batch('train')\n",
    "print(f'inputs: {xb}\\ninputs_shape: {xb.shape}\\n')\n",
    "print(f'inputs: {yb}\\ninputs_shape: {yb.shape}\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: [11]\ttarget: 0\n",
      "input: [11, 0]\ttarget: 32\n",
      "input: [11, 0, 32]\ttarget: 46\n",
      "input: [11, 0, 32, 46]\ttarget: 39\n",
      "input: [11, 0, 32, 46, 39]\ttarget: 58\n",
      "input: [11, 0, 32, 46, 39, 58]\ttarget: 1\n",
      "input: [11, 0, 32, 46, 39, 58, 1]\ttarget: 61\n",
      "input: [11, 0, 32, 46, 39, 58, 1, 61]\ttarget: 47\n",
      "input: [43]\ttarget: 50\n",
      "input: [43, 50]\ttarget: 53\n",
      "input: [43, 50, 53]\ttarget: 11\n",
      "input: [43, 50, 53, 11]\ttarget: 0\n",
      "input: [43, 50, 53, 11, 0]\ttarget: 21\n",
      "input: [43, 50, 53, 11, 0, 21]\ttarget: 52\n",
      "input: [43, 50, 53, 11, 0, 21, 52]\ttarget: 1\n",
      "input: [43, 50, 53, 11, 0, 21, 52, 1]\ttarget: 58\n",
      "input: [53]\ttarget: 53\n",
      "input: [53, 53]\ttarget: 1\n",
      "input: [53, 53, 1]\ttarget: 50\n",
      "input: [53, 53, 1, 50]\ttarget: 47\n",
      "input: [53, 53, 1, 50, 47]\ttarget: 58\n",
      "input: [53, 53, 1, 50, 47, 58]\ttarget: 58\n",
      "input: [53, 53, 1, 50, 47, 58, 58]\ttarget: 50\n",
      "input: [53, 53, 1, 50, 47, 58, 58, 50]\ttarget: 43\n",
      "input: [32]\ttarget: 47\n",
      "input: [32, 47]\ttarget: 57\n",
      "input: [32, 47, 57]\ttarget: 1\n",
      "input: [32, 47, 57, 1]\ttarget: 53\n",
      "input: [32, 47, 57, 1, 53]\ttarget: 52\n",
      "input: [32, 47, 57, 1, 53, 52]\ttarget: 43\n",
      "input: [32, 47, 57, 1, 53, 52, 43]\ttarget: 1\n",
      "input: [32, 47, 57, 1, 53, 52, 43, 1]\ttarget: 58\n"
     ]
    }
   ],
   "source": [
    "# input and target mapping for batches\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f'input: {context.tolist()}\\ttarget: {target}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
